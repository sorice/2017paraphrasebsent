{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>This notebook was put together by [Abel Meneses-Abad](http://www.menesesabad.com) for Paper *Paraphrase Beyond Sentence*. Source and license info is on [GitHub](https://github.com/sorice/2017paraphrasebsent/).</i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "\n",
    "Having a normalized corpus or a fiturized corpus, the first step is to normalize, clean, scale those features. In Big Data the number of features (or # of columns) is always exponential. For example 35 features in 5M rows runs ok in a laptop, but only incrementing to 40 features the problem could be considered Big Data [<a href=\"#Bilbro2019\" title=\"Visual Diagnostics at Scale\"> (Bilbro2019) </a>](#Bilbro2019).\n",
    "\n",
    "Feature Selection it is impossible or problematic, some times, without scaling or cleanning the data properly. As you will see at the end of this chapter, the number of features doesn't increase mandatory the accuracy of Machine Learning models. In order to incrase the future number of useful features those not-important must be detected and eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# use seaborn plotting style defaults\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import textsim\n",
    "len(textsim.__all_distances__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From CSV to Sklearn Bunch\n",
    "\n",
    "Loading csv file in Sklearn style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "with open('data/MSRPC-2004/msrpc.csv') as csv_file:\n",
    "    data_file = csv.reader(csv_file)\n",
    "    temp = next(data_file)\n",
    "    n_samples = int(temp[0])\n",
    "    n_features = int(temp[1])\n",
    "    target_names = np.array(temp[2:4])\n",
    "    temp = next(data_file)\n",
    "    feature_names = np.array(temp[:-2])\n",
    "    data = np.empty((n_samples, n_features))\n",
    "    target = np.empty((n_samples), dtype=np.int)\n",
    "    index = np.empty((n_samples), dtype=np.int)\n",
    "    \n",
    "    for i, ir in enumerate(data_file):\n",
    "        data[i] = np.asarray(ir[:-2], dtype=np.float)\n",
    "        target[i] = np.asarray(ir[-1], dtype=np.int)\n",
    "        index[i] = np.asarray(ir[-2], dtype=np.int)\n",
    "\n",
    "    fdescr = 'Microsoft Research Corpus'\n",
    "        \n",
    "msrpc = Bunch(data=data, target=target,\n",
    "    target_names=target_names,\n",
    "    DESCR=fdescr,\n",
    "    feature_names=feature_names)\n",
    "\n",
    "x = msrpc['data']\n",
    "Y = msrpc['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5786, 43)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msrpc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['binary_distance', 'braycurtis_distance', 'canberra_distance',\n",
       "        'chebyshev_distance', 'containment_distance',\n",
       "        'correlation_distance', 'cosine_distance',\n",
       "        'damerau_levenshtein_distance', 'dice_coefficient',\n",
       "        'dice_distance', 'edit_similarity', 'euclidean_distance',\n",
       "        'hamming_distance', 'interval_distance', 'jaccard_distance',\n",
       "        'jaro_distance', 'jaro_winkler_distance', 'kulsinski_distance',\n",
       "        'lcs_distance', 'lcs_similarity', 'levenshtein_distance',\n",
       "        'mahalanobis_distance', 'manhattan_distance', 'masi_distance',\n",
       "        'match_rating_comparison', 'matching_coefficient',\n",
       "        'matching_coefficient_pablo', 'matching_distance',\n",
       "        'minkowski_distance', 'needleman_wunsch_distance',\n",
       "        'needleman_wunsch_similarity', 'overlap_distance',\n",
       "        'qgram_distance', 'rogerstanimoto_distance', 'russellrao_distance',\n",
       "        'seuclidean_distance', 'smith_waterman_distance',\n",
       "        'sokalmichener_distance', 'sokalsneath_distance',\n",
       "        'sqeuclidean_distance', 'token_containment_distance',\n",
       "        'token_hamming_distance', 'yule_distance'], dtype='<U28'),\n",
       " 43)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names,len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan [1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(x.mean(),Y[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The mean value can't be obtained due to *'NaN'* values inside data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n",
    "\n",
    "Read the page 102 of the book \"Python Machine Learning Unlock deeper insights ...\" [<a href=\"#Raschka2015\" title=\"Python Machine Learning Book\"> (Raschka2015) </a>](#Raschka2015).\n",
    "\n",
    "After some experiments we consider better to convert numpy.array in a pandas.DataFrame structure because can be useful to change *Nan* values by the median or mean of the column when the value is, this kind of operation with np is not possible (np.where and pd.where are differents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(msrpc.data, columns=msrpc.feature_names, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correlation_distance</th>\n",
       "      <th>seuclidean_distance</th>\n",
       "      <th>yule_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.690416</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5730</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5763</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.477226</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5764</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      correlation_distance  seuclidean_distance  yule_distance\n",
       "16                     1.0             3.464102            NaN\n",
       "35                     1.0             4.000000            NaN\n",
       "161                    0.0                  NaN            0.5\n",
       "176                    1.0             4.690416            NaN\n",
       "217                    NaN             3.162278            NaN\n",
       "...                    ...                  ...            ...\n",
       "5651                   1.0             4.472136            NaN\n",
       "5730                   1.0             4.472136            NaN\n",
       "5759                   1.0             4.000000            NaN\n",
       "5763                   1.0             5.477226            NaN\n",
       "5764                   1.0             4.242641            NaN\n",
       "\n",
       "[183 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding null values\n",
    "col_mask=df.isnull().any(axis=0) \n",
    "row_mask=df.isnull().any(axis=1)\n",
    "df.loc[row_mask,col_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yule_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5730</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5763</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5764</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      yule_distance\n",
       "16              NaN\n",
       "35              NaN\n",
       "176             NaN\n",
       "217             NaN\n",
       "228             NaN\n",
       "...             ...\n",
       "5651            NaN\n",
       "5730            NaN\n",
       "5759            NaN\n",
       "5763            NaN\n",
       "5764            NaN\n",
       "\n",
       "[167 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing, but still problems\n",
    "df.replace(np.nan, df.mean(), inplace=True)\n",
    "col_mask=df.isnull().any(axis=0) \n",
    "row_mask=df.isnull().any(axis=1)\n",
    "df.loc[row_mask,col_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing inf by max and -inf by min\n",
    "mask = df['yule_distance'] != np.inf\n",
    "df.loc[~mask, 'yule_distance'] = df.loc[mask, 'yule_distance'].max()\n",
    "bmask = df['yule_distance'] != -np.inf\n",
    "df.loc[~bmask, 'yule_distance'] = df.loc[bmask, 'yule_distance'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3010968741795017\n"
     ]
    }
   ],
   "source": [
    "#Replacing inf and -inf by the mean of the rest of the values\n",
    "is_inf = df.yule_distance == np.inf \n",
    "is_ninf = df.yule_distance == -np.inf\n",
    "yule_mean = df.yule_distance[~is_inf & ~is_ninf].mean()\n",
    "print(yule_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_distance                   0.000000\n",
      "braycurtis_distance               0.341267\n",
      "canberra_distance                11.244317\n",
      "chebyshev_distance                1.179571\n",
      "containment_distance              0.756179\n",
      "correlation_distance              1.073415\n",
      "cosine_distance                   0.687943\n",
      "damerau_levenshtein_distance     52.452471\n",
      "dice_coefficient                  0.589374\n",
      "dice_distance                     0.219358\n",
      "edit_similarity                   0.565265\n",
      "euclidean_distance                3.442548\n",
      "hamming_distance                105.863118\n",
      "interval_distance                11.561182\n",
      "jaccard_distance                  0.564055\n",
      "jaro_distance                     0.765100\n",
      "jaro_winkler_distance             0.802584\n",
      "kulsinski_distance                0.348925\n",
      "lcs_distance                     84.088144\n",
      "lcs_similarity                    0.709653\n",
      "levenshtein_distance             52.492223\n",
      "mahalanobis_distance              8.794717\n",
      "manhattan_distance               11.985482\n",
      "masi_distance                     0.855458\n",
      "match_rating_comparison           0.523159\n",
      "matching_coefficient             24.909264\n",
      "matching_coefficient_pablo        0.381136\n",
      "matching_distance                 0.514637\n",
      "minkowski_distance               11.985482\n",
      "needleman_wunsch_distance       104.984445\n",
      "needleman_wunsch_similarity       0.948028\n",
      "overlap_distance                  0.640985\n",
      "qgram_distance                    0.589374\n",
      "rogerstanimoto_distance           0.291993\n",
      "russellrao_distance               0.344455\n",
      "seuclidean_distance               4.761386\n",
      "smith_waterman_distance         134.378500\n",
      "sokalmichener_distance            0.291993\n",
      "sokalsneath_distance              0.441653\n",
      "sqeuclidean_distance             12.437608\n",
      "token_containment_distance        0.593774\n",
      "token_hamming_distance            0.514637\n",
      "yule_distance                     1.301097\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yule_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5730</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5763</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5764</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      yule_distance\n",
       "16              NaN\n",
       "35              NaN\n",
       "176             NaN\n",
       "217             NaN\n",
       "228             NaN\n",
       "...             ...\n",
       "5651            NaN\n",
       "5730            NaN\n",
       "5759            NaN\n",
       "5763            NaN\n",
       "5764            NaN\n",
       "\n",
       "[167 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing, the inf & -inf by the mean of the rest\n",
    "df.replace([np.inf, -np.inf], df.yule_distance[~is_inf & ~is_ninf].mean(), inplace=True)\n",
    "print(df.mean())\n",
    "col_mask=df.isnull().any(axis=0) \n",
    "row_mask=df.isnull().any(axis=1)\n",
    "df.loc[row_mask,col_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason the yule_distance still have __NaN__ values. So in the next block this problem is fixed writing directly to the cells with those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[row_mask,col_mask] = yule_mean\n",
    "col_mask=df.isnull().any(axis=0) \n",
    "row_mask=df.isnull().any(axis=1)\n",
    "df.loc[row_mask,col_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here also you can experiment that pd.DataFrame interpolation and fillna, ffill, all those methods fail when remain some inf or -inf values.\n",
    "\n",
    "    df.interpolate()\n",
    "    \n",
    "OR    \n",
    "\n",
    "    df.fillna(method='ffill')\n",
    "    \n",
    "OR\n",
    "\n",
    "    df.fillna(dff.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally this classical method with sklearn was implemented but (read the note)\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "imr = SimpleImputer(missing_values=NaN, strategy='mean')\n",
    "imr = imr.fit(x)\n",
    "X = imr.transform(x)\n",
    "print(X.shape)\n",
    "```\n",
    "(5786, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** After some experiments was discovered a shape change in the data matrix because of the *Imputer* method. This change of shape isn't commented in any readed book until now. Imputer method is showed here because it is the classic example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Transforming all features to the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002 19.270003160896454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "X = df\n",
    "# A varian & Recomended: scale the data such that mean = 0 and standard deviation = 1\n",
    "# see \"Python Machine Learning Unlock deeper insights ...\" (Raschka2015), pag 111, first paragrah.\n",
    "X_s = scale(X,with_mean=True,with_std=True,axis=0)\n",
    "\n",
    "# B variant: Second way to scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X_s2 = mms.fit_transform(X)\n",
    "\n",
    "# C variant & Recomended: Same as way A\n",
    "# see \"Python Machine Learning Unlock deeper insights ...\" (Raschka2015), pag 111, first paragrah.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X_s3 = stdsc.fit_transform(X)\n",
    "\n",
    "print(np.max(X_s2), np.max(X_s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning a dataset in training and test sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_s, Y, test_size=0.3, random_state=4)\n",
    "Xs_train, Xs_test, Ys_train, Ys_test = train_test_split(X_s2, Y, test_size=0.3, random_state=4)\n",
    "\n",
    "input_dataset = np.column_stack([X_s,Y]) #Auxiliar dataset array for printing\n",
    "train,test=train_test_split(input_dataset,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5786, 43), (5786, 43))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_s.shape, X_s2.shape, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (4050,), numpy.ndarray)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train), train[:,-1].shape, type(X_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving obtained clean data for future notebooks\n",
    "import pickle\n",
    "data = [X_s, Y]\n",
    "positive_split_scaled_data = [X_s2, Y, msrpc.feature_names, index]\n",
    "pickle.dump(data, open('data/cleaned-scaled-data.pkl', 'wb'))\n",
    "pickle.dump(positive_split_scaled_data, open('data/clean-scaled-positive-data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Read the page 118 of the book \"Python Machine Learning Unlock deeper insights ...\" (Raschka2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: SelectKBest doesn't work with none positive values, we use x_s2 for that reason.\n",
    "x_n = feature_selection.SelectKBest(chi2, k=10).fit_transform(x_s2, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5786, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBS():\n",
    "    def __init__(self, estimator, k_features,\n",
    "        scoring=accuracy_score,\n",
    "        test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "                train_test_split(X, y, test_size=self.test_size,\n",
    "                                    random_state=self.random_state)\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train,\n",
    "                                    X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "        \n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "            \n",
    "            for p in combinations(self.indices_, r=dim-1):\n",
    "                score = self._calc_score(X_train, y_train,\n",
    "                                            X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self, X_train, y_train,\n",
    "                            X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SBS at 0x7f91ce483a20>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#forest = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#logreg = LogisticRegression()\n",
    "#from sklearn.svm import SVC\n",
    "#clf = SVC(kernel='linear')\n",
    "#forest.fit(Xs_train, ys_train)\n",
    "sbs = SBS(knn, k_features=1)\n",
    "sbs.fit(Xs_train, ys_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbs.scores_.index(max(sbs.scores_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.reset_orig()\n",
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "plt.plot(k_feat, sbs.scores_, marker='o')\n",
    "plt.ylim([0.1, 1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['braycurtis_distance' 'canberra_distance' 'containment_distance'\n",
      " 'correlation_distance' 'cosine_distance' 'damerau_levenshtein_distance'\n",
      " 'dice_coefficient' 'dice_distance' 'edit_similarity' 'euclidean_distance'\n",
      " 'hamming_distance' 'interval_distance' 'jaccard_distance'\n",
      " 'jaro_winkler_distance' 'lcs_distance' 'lcs_similarity'\n",
      " 'levenshtein_distance' 'mahalanobis_distance' 'manhattan_distance'\n",
      " 'masi_distance' 'match_rating_comparison' 'matching_distance'\n",
      " 'minkowski_distance' 'overlap_distance' 'qgram_distance'\n",
      " 'russellrao_distance' 'seuclidean_distance' 'smith_waterman_distance'\n",
      " 'sokalsneath_distance' 'token_containment_distance'\n",
      " 'token_hamming_distance' 'yule_distance']\n"
     ]
    }
   ],
   "source": [
    "k5 = list(sbs.subsets_[11])\n",
    "print(feature_names[k5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['braycurtis_distance' 'canberra_distance' 'containment_distance'\n",
      " 'correlation_distance' 'cosine_distance' 'damerau_levenshtein_distance'\n",
      " 'dice_coefficient' 'dice_distance' 'edit_similarity' 'euclidean_distance'\n",
      " 'interval_distance' 'jaccard_distance' 'jaro_winkler_distance'\n",
      " 'lcs_distance' 'lcs_similarity' 'levenshtein_distance'\n",
      " 'mahalanobis_distance' 'manhattan_distance' 'masi_distance'\n",
      " 'match_rating_comparison' 'matching_distance' 'qgram_distance'\n",
      " 'russellrao_distance' 'token_containment_distance' 'yule_distance']\n"
     ]
    }
   ],
   "source": [
    "k5 = list(sbs.subsets_[18])\n",
    "print(feature_names[k5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Code from page 124 of the book \"Python Machine Learning Unlock deeper insights ...\" (Raschka2015).\n",
    "\n",
    "**Note**: This kind of evaluation of features, just assigned a rank to distances, but no group them or rerank it to get the most N important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "forest.fit(Xs_train, ys_train)\n",
    "importances = forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) binary_distance                0.048133\n",
      " 2) braycurtis_distance            0.044258\n",
      " 3) canberra_distance              0.043619\n",
      " 4) chebyshev_distance             0.043532\n",
      " 5) containment_distance           0.043129\n",
      " 6) correlation_distance           0.042648\n",
      " 7) cosine_distance                0.041479\n",
      " 8) damerau_levenshtein_distance   0.033021\n",
      " 9) dice_coefficient               0.032869\n",
      "10) dice_distance                  0.032439\n",
      "11) edit_similarity                0.026952\n",
      "12) euclidean_distance             0.026231\n",
      "13) hamming_distance               0.025166\n",
      "14) interval_distance              0.023963\n",
      "15) jaccard_distance               0.023732\n",
      "16) jaro_distance                  0.023471\n",
      "17) jaro_winkler_distance          0.023430\n",
      "18) kulsinski_distance             0.023347\n",
      "19) lcs_distance                   0.023018\n",
      "20) lcs_similarity                 0.022648\n",
      "21) levenshtein_distance           0.022596\n",
      "22) mahalanobis_distance           0.021664\n",
      "23) manhattan_distance             0.021628\n",
      "24) masi_distance                  0.021604\n",
      "25) match_rating_comparison        0.021500\n",
      "26) matching_coefficient           0.021153\n",
      "27) matching_coefficient_pablo     0.018560\n",
      "28) matching_distance              0.017587\n",
      "29) minkowski_distance             0.017584\n",
      "30) needleman_wunsch_distance      0.017411\n",
      "31) needleman_wunsch_similarity    0.016887\n",
      "32) overlap_distance               0.016806\n",
      "33) qgram_distance                 0.015451\n",
      "34) rogerstanimoto_distance        0.014370\n",
      "35) russellrao_distance            0.014249\n",
      "36) seuclidean_distance            0.014188\n",
      "37) smith_waterman_distance        0.013525\n",
      "38) sokalmichener_distance         0.013455\n",
      "39) sokalsneath_distance           0.013445\n",
      "40) sqeuclidean_distance           0.013397\n",
      "41) token_containment_distance     0.003472\n",
      "42) token_hamming_distance         0.002383\n",
      "43) yule_distance                  0.000000\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(Xs_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, feature_names[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "The data preparation is a very important step in Machine Learning process. Its understanding implied full knowledge of file operations, data behaviour, math implications of missing or non-scaled values, the validation process implications with train and test data, outliers significance and feature selection importance to improve the accuracy of our models.\n",
    "\n",
    "Section *model evaluation example* shows that with only 10 features is possible to get results over 0.74 in accuracy metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendations\n",
    "\n",
    "* Read about **unregularized models** where *dimensionality reduction* via feature selection, is an alternative way to reduce the complexity of the model and avoid overfitting.\n",
    "\n",
    "* Study the way to introduce Stritified Kfold data in real experiments to fix the seeds and make comparable the results between different classifiers. [see 4.4](04.4-Classification) for kfold analysis of multiple classifiers.\n",
    "\n",
    "* Sklearn Bunch is a more complicated structure than pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "* Test feature selection in sparse data with linear models like Lasso or Logistic Regresion.\n",
    "* Use the class SelectFromModel inside feature_selection module, and try different classification models like svm, knn, etc.\n",
    "* Make a secuence of feature selection with SVM and a set of kernels like RBF ('rbf'), Gram Matrix ('precomputed'), Cosine('cosine'), 'linear', Polinomial('poly'), Sigmoid and a self kernel. Compare the selected features and their rank. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and Resources\n",
    "\n",
    "* Rebecca Bilbro, \"Visual Diagnostics at Scale\". SciPy Conference, 2019.\n",
    "<a id='Bilbro2019'></a>\n",
    "\n",
    "* Sebastian Raschka, Book \"Python Machine Learning\". Packt Publishing, 2015.\n",
    "<a id='Raschka2015'></a>\n",
    "\n",
    "* Gopi Subramanian, Book \"Python Data Science Cookbook\". Packt Publishing, 2015.\n",
    "<a id='Subramanian2015'></a>\n",
    "\n",
    "* Alberto Boschetti & Luca Massaron, Book \"Python Data Science Essential\". Packt Publishing, 2015.\n",
    "<a id='Boschetti2015'></a>\n",
    "\n",
    "* Trent Hauck, Book \"Scikit-learn Cookbook\". Packt Publishing, 2014.\n",
    "<a id='Hauck2015'></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
