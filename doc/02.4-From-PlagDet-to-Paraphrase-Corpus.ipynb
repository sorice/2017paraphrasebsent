{
 "metadata": {
  "name": "",
  "signature": "sha256:70141e0e659459b6de1eedabc7e6e7733dbca6ec2e0ad395bf81c3e16c206027"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<small><i>This notebook was put together by [Abel Meneses-Abad](http://www.menesesabad.com) for SciPy LA Habana 2017. Source and license info is on [github repository](http://github.com/sorice/simtext_scipyla2017).</i></small>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Transforming PlagDet into a Paraphrase Identification Corpus\n",
      "\n",
      "The objetive of this notebook is to show the implemented process to convert a classic plagiarism detection corpus (sometimes referred as *text-reuse corpus*) into a fragment-pairs based paraphrase identification corpus."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plagiarism Detection Corpus\n",
      "\n",
      "The original Plagiarism Detection Corpus of PAN-13 (citar) have two parts the train and test parts.\n",
      "Every one of them have the following structure:\n",
      "\n",
      "    PAN-13-text-alignment-corpus\n",
      "        pairs                           -> list of text names tuple on susp & src to compare\n",
      "        susp/                           -> susp directory containing all suspicious text\n",
      "        src/                            -> src directory containing all text reuse source files\n",
      "        01-no-plagiarism/               -> a directory containing an XML file per no-plag case on pairs file\n",
      "        02-no-obfuscation/              -> a directory containing an XML file per copy-paste case on pairs file\n",
      "        03-random-obfuscation/          -> a directory containing an XML file per random paraphrase case on pairs file\n",
      "        04-translation-obfuscation/     -> a directory containing an XML file per cross-lingual text-reuse case on pairs file\n",
      "        05-summary-obfuscation/         -> a directory containing an XML file per paraphrase case of summary type on pairs file\n",
      "        \n",
      "Here is an example of the XML structure of a case, *03-random-obfuscation/suspicious-document00007-source-document00382.xml*:\n",
      "\n",
      "<body>\n",
      "<pre style=\"color:#1f1c1b;background-color:#ffffff;\">\n",
      "<b>&lt;document</b><span style=\"color:#006e28;\"> reference=</span><span style=\"color:#aa0000;\">&quot;suspicious-document00007.txt&quot;</span><b>&gt;</b>\n",
      "<b>&lt;feature</b><span style=\"color:#006e28;\"> name=</span><span style=\"color:#aa0000;\">&quot;plagiarism&quot;</span><span style=\"color:#006e28;\"> obfuscation=</span><span style=\"color:#aa0000;\">&quot;random&quot;</span><span style=\"color:#006e28;\"> obfuscation_degree=</span><span style=\"color:#aa0000;\">&quot;0.4694788492120119&quot;</span><span style=\"color:#006e28;\"> source_length=</span><span style=\"color:#aa0000;\">&quot;453&quot;</span><span style=\"color:#006e28;\"> source_offset=</span><span style=\"color:#aa0000;\">&quot;0&quot;</span><span style=\"color:#006e28;\"> source_reference=</span><span style=\"color:#aa0000;\">&quot;source-document00382.txt&quot;</span><span style=\"color:#006e28;\"> this_length=</span><span style=\"color:#aa0000;\">&quot;453&quot;</span><span style=\"color:#006e28;\"> this_offset=</span><span style=\"color:#aa0000;\">&quot;9449&quot;</span><span style=\"color:#006e28;\"> type=</span><span style=\"color:#aa0000;\">&quot;artificial&quot;</span> <b>/&gt;</b>\n",
      "<b>&lt;/document</b><b>&gt;</b>\n",
      "</pre>\n",
      "</body>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, this case refers two documents (suspicious-document00007.txt, source-document00382.txt) and inside each one a fragment. After some processing you can see both fragments of text. The xml establish a *paraphrase* type (also *obfuscation* in this corpus), the boundaries (*offset*,*length*) for both documents, a degree of paraphrase and the way in wich this case was generated.\n",
      "\n",
      "**Note:** some XMLs of this corpus may contain more than one pair of fragments."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run scripts/readText_fromXML.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table width='400' cellpadding='4' cellspacing='0'>\n",
        "        <col width='128*'>\n",
        "        <col width='128*'>\n",
        "        <tr valign='top'>\n",
        "            <td width='45*'>\n",
        "                <p><b>Susp</b></p>\n",
        "            </td>\n",
        "            <td width='45*'>\n",
        "                <p><b>Src</b></p>\n",
        "            </td>\n",
        "        </tr>\n",
        "        <tr valign='top'>\n",
        "            <td width='45*'>\n",
        "                <p> Special@ tamu. edu DJ of Regulation storage tissue and the use from Cadet of\n",
        "crop improvement. Hannapel Plant,\n",
        "Miller Marchetti& Park wd (1985): 700-703 plant of Potato Acid Physiol78 Accumulation by wdpark Tuber.\n",
        "Manipulation Protein\u00a0 Publications list of gibberellic Patents submitted, am, MA JC, wd Park (1998) release in biotechnology and Jacinto, two long rice grain varieties having pubmed processing quality. Mcclung for Plant Variety Protection  </p>\n",
        "            </td>\n",
        "            <td width='45*'>\n",
        "                <p> wdpark@tamu.edu\n",
        "Manipulation of plant storage tissue and the use of biotechnology in crop improvement.\n",
        "Hannapel DJ, Miller JC & Park WD (1985) : 700-703 Regulation of Potato Tuber Protein Accumulation by Gibberellic Acid. Plant Physiol78\n",
        "\u00a0\n",
        "Publications list from Pubmed\n",
        "Patents\n",
        "McClung, AM, MA Marchetti, WD Park (1998) Release of Cadet and Jacinto, two long grain rice varieties having special processing quality. Submitted for Plant Variety Protection </p>\n",
        "            </td>\n",
        "        </tr>\n",
        "    </table>"
       ],
       "metadata": {},
       "output_type": "display_data"
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Paraphrase Identification Corpus\n",
      "\n",
      "A classic corpus of paraphrase identification may contain different structures of paraphrase cases. Usually the structure could be:\n",
      "\n",
      "    id class sentence-1 sentence-2\n",
      "    \n",
      "And the class could be equal to *0* or *1*, wich means *non-paraphrase* and *paraphrase*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Overview of the Problem of Plagiarism to Paraphrase Corpus Transformation\n",
      "\n",
      "Broadly speaking in a plagiarism detection issue you must detect(or extract) the two fragments(suspicious and source) using some approaches (citation measures, word fingerprints, ngrams, etc.), the problem is to find the boundaries of both fragments usually inside large documents).\n",
      "\n",
      "But, in a paraphrase detection problem it must be detected if two sentences are paraphrased or not, and a very common technique here is to convert the original structure of a case in a machine learning object: a vector of features based on the *$original_{sentence}$*, the *$paraphased_{sentence}$* and the class _paraphrased/non-paraphrased_ .\n",
      "\n",
      "As you can see on linguist international investigation about paraphrase, there is a wide range of definitions, for that reason we will like to define a concept.\n",
      "\n",
      "**Paraphrase Definition:** *$class = 1$ (paraphrased) if there is some kind of transformation maintaining a high semantic similarity degree [<a href=\"#Vila2014\" title=\"Is This a Paraphrase ? What Kind ? Paraphrase Boundaries and Typology\"> (Vila2014, p. 6)</a>](#Vila2014), and $class = 0$ (non-paraphrased)if both text are dissimilar even if they speak about the same semantic field but differs on meanning in some degree.*\n",
      "\n",
      "After normalization evaluation (see the resultant structure in [Normalization-Alignment-Quality Notebook](02.4-Normalization-Alignment-Quality.ipynb)) the porpouse of this pipeline's step is to obtain a corpus with the follow structure:\n",
      "\n",
      "* $(case_{id}, text_{fragment_{1}}, text_{fragment_{2}}, binary\\,class)$\n",
      "\n",
      "previous generated structures:\n",
      "\n",
      "* Output structure after alignment subprocess:\n",
      "\n",
      "$(id_K,normalized-sentence_K,original\\,offset_{sentence\\,K},original\\,offset+length_{sentence\\,K})$\n",
      "\n",
      "* Output structure after quality norm subprocess:\n",
      "\n",
      "$(id_{sentence_P\\,susp},offset_{sentence_P},offset+length_{sentence_P},\\%\\,sentence_{P}\\, \\in\\,susp_{fragment\\,X},id_{fragment\\,X})$\n",
      "\n",
      "Then in the remainder notebooks anew this structure will be used to apply machine learning.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## A New Paraphrase Identification Corpus at Fragment Level\n",
      "\n",
      "TODO: excepci\u00f3n cuando no queda ninguna oraci\u00f3n en el fragmento.\n",
      "\n",
      "### Generating TRUE Cases"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scripts import PANXml\n",
      "import pandas as pd\n",
      "import time\n",
      "\n",
      "xmlColecctionPath = '../orig/paraph/'\n",
      "alignedCollectionPath = '../align/'\n",
      "origCollectionPath = '../'\n",
      "\n",
      "timei = time.time()\n",
      "with open('../align/TRUE_paraph_aligned_pairs') as casePairs:\n",
      "    for docs in casePairs:\n",
      "        susp, src = docs.split()\n",
      "        case = PANXml(xmlColecctionPath+susp[:-4]+'-'+src[:-4]+'.xml')\n",
      "        newCase = {}\n",
      "        \n",
      "        #Load Quality Matrix per case\n",
      "        QM = pd.read_csv(alignedCollectionPath+'quality/'+susp+' '+src,\n",
      "                           names=['sentID','offset','length','percent','FragID'],\n",
      "                           delimiter = '\\t')\n",
      "        \n",
      "        #Analyse the fragment pairs list in the xml case\n",
      "        if case.fragmentList != []: #this line filter non-paraphrased XML\n",
      "            for id, frag in enumerate(case.fragmentList):\n",
      "                text = {'susp/':'','src/':''}\n",
      "\n",
      "                #For every doc in the pair\n",
      "                for doc,file_type in zip([susp,src],['susp/','src/']):\n",
      "                    targetID = int(str(id+1)+doc[-9:-4])\n",
      "                    docText = open(origCollectionPath+file_type+doc)\n",
      "                    offsetf = len(docText.read())\n",
      "                    docText.close()\n",
      "                    lenf = 0\n",
      "\n",
      "                    #Load aligned matrix for doc\n",
      "                    AM = pd.read_csv(alignedCollectionPath+file_type+doc,\n",
      "                                     names=['id','sent','offset','length'], \n",
      "                                     sep='\\t')\n",
      "                    \n",
      "                    #Join correspondent aligned sentences in a single fragment\n",
      "                    for idx in QM.index:\n",
      "                        if QM.FragID[idx] == targetID:\n",
      "                            offsetf = min(offsetf,QM.offset[idx])\n",
      "                            lenf = max(lenf,QM.length[idx])\n",
      "                            text[file_type] +=  AM.sent[QM.sentID[idx]]+' '\n",
      "\n",
      "                #Take both created fragment per doc and create a pair fragment case\n",
      "                newCaseID = str(id+1)+susp[-9:-4]+src[-9:-4]\n",
      "                if case.fragmentList != []:\n",
      "                    caseClass = 1\n",
      "                newCase[newCaseID] = str(newCaseID)+'\\t'+text['susp/']+'\\t'+text['src/']+'\\t'+str(caseClass)+'\\n'\n",
      "            \n",
      "            #Write the positive cases corpus\n",
      "            paraphCorpus = open('../PAN-True-Paraphrase-Corpus','a')\n",
      "            for value in newCase.values():\n",
      "                paraphCorpus.write(value)\n",
      "            paraphCorpus.close()\n",
      "print('Total time:', time.time() - timei)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total time: 3.68674635887146\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The Problem of the Generation of Non-Paraphrased Cases\n",
      "\n",
      "The last hard problem to describe after ending is that of the empty *non-plagiarism* XML cases (contained on the *01-no-plagiarism/* folder).  Those XMLs are empty or have a different structure, only across the xml file name you can figure out what texts doesn't have text similarities (See the _suspicious-document00017-source-document00534.xml_ example below). How to solve that? \n",
      "\n",
      "<body>\n",
      "<pre style='color:#1f1c1b;background-color:#ffffff;'>\n",
      "<b>&lt;document</b><span style='color:#006e28;'> reference=</span><span style='color:#aa0000;'>&quot;suspicious-document00017.txt&quot;</span><b>&gt;</b>\n",
      "<b>&lt;/document</b><b>&gt;</b>\n",
      "</pre>\n",
      "</body>\n",
      "\n",
      "Once we have both dissimilar entire texts, we must select two fragments with some shallow properties similar to the positive cases. Why must they share some properties? (E.g. close vocabulary) Because these could help to identify the features with latent semantic identification capacities in the following phases. Attending to machine learning problems modeling properties a not balanced corpus is proposed, with a 66% of non-paraphrased cases.\n",
      "\n",
      "__Note__: Another approach of *non-paraphrased cases* could be the use of a set of copy-paste cases (similar pairs of text but not paraphrased). For this alternative analysis, or related, the author propose a set of experiments described in an special notebook not contained in this tutorial."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Details of Non-Paraphrased Cases Generator Algorithm\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "../align/FALSE_paraph_aligned_pairs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Generating whole Collection Non-Paraphrase Cases"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run scripts/02.5_nonParaphrasedCasesGenerationj.py ../align/FALSE_paraph_aligned_pairs ../PAN-True-Paraphrase-Corpus ../susp ../src ../"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: File `'scripts/02.5_nonParaphrasedCasesGenerationj.py'` not found.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Background on Text Similarity Problems\n",
      "\n",
      "Text similarity is a popular field of investigation with many problems very close in meaning but very different in fact. To a better understanding of this notebook we show you a short background on the main problems of this area and a short definition.\n",
      "\n",
      "- __Semantic Text Similarity__: Given two sentences you must calculate the degree of similarity and classify them. Usually this is a multi-class problem with 6 classes.\n",
      "- __Textual Entailment__: Identify if two texts are related in one direction (A implicate B).\n",
      "- __Text Similarity__: Given two text fragments you must identify if they are semantic related in both directions.\n",
      "- __Text Alignment__: Given two different text you must match every sentence in text A with its correspondending sentence in text B.\n",
      "- __Paraphrase Identification__: Given two sentences you must classify if they are paraphrased or not (binary classification).\n",
      "- __Text Reuse__: Detect in a text collection reused fragments in a single text taken from another document.\n",
      "- __Plagiarism Detection__ (_Text Reuse + Citation Analysis_): Detect in a text collection pairs of non-quoted fragments with the same meaning.\n",
      "- __Machine Translation__: Align text pairs with same meaning but in different language.\n",
      "        \n",
      "Then the approach presented in this tutorial is a *Text Similarity* problem seen from the perspective of a *Paraphrase Identification* problem.\n",
      "\n",
      "### Corpus of Text Reuse\n",
      "\n",
      "PAN-PC / TNLP / Plagiarism Corpus / \n",
      "\n",
      "### Corpus of Paraphrase Identification\n",
      "\n",
      "MSRPC / STS /"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Conclusions\n",
      "\n",
      "The main objective of this notebook was accomplished:\n",
      "\n",
      "    \"After having the aligned normalized-texts, a new pair-chunks vs paraphrase-class corpus was generated from the xmls of PAN-PC corpus.\"\n",
      "    \n",
      "The true cases are generated in the first place. This part of the process is simple and fast, because chunk information is full contained in the xmls of PAN-PC corpus.\n",
      "\n",
      "However, non paraphrased cases (or false cases) must be constructed mathematically due to the lack of information of non-paraphrased xmls of PAN-PC corpus.\n",
      "\n",
      "# Recomendations\n",
      "\n",
      "For future experiments the best way to accomplis this task is to generate non-paraphrased pair of texts manually; that is humanly designed.\n",
      "\n",
      "Is vague the final porpouse or the applications of the machine learning models generated with this new corpus."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Questions\n",
      "\n",
      "* Analyze the _func_ __getFeatureVector__ and try with other mathematical ecuations. Do only 100 new cases and analyze the actual result against previous.\n",
      "* Make a parallel version for the non-paraphrased cases.\n",
      "* Analyze the possibility to have a multi class corpus based on Verbatim/Paraphrased/Non-paraphrased cases, taking into acount that every kind of similarity measure will have a high score in both Verbatim & Paraphrased cases."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# References and Resources\n",
      "\n",
      "* Vila, Marta & Mart\u00ed, M Ant\u00f2nia & Rodr\u00edguez, Horacio \"Is This a Paraphrase ? What Kind ? Paraphrase Boundaries and Typology\". Open Journal of Modern Linguistics, 2014.\n",
      "<a id='Vila2014'></a>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}