{
 "metadata": {
  "name": "",
  "signature": "sha256:9c960cf7a495bba545767212868abfe42fe7611885818229adcb6dc278a1632e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Text Similarity Example with Sklearn\n",
      "\n",
      "El objetivo de este notebook es mostrar una serie de pasos para realizar similitud entre dos cadenas de textos utilizando\n",
      "modelos de textos vectoriales. En el ejemplo se utilizan medididas de similitud configuradas para trabajar con t\u00e9rminos, tokens\n",
      "o palabras."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 1 From String to Vectors\n",
      "\n",
      "Introducir las cadenas y convertir a dos vectores, utilizando NLTK."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "sA = \"PCCW's chief operating officer, Mike Butcher, and Alex Arena, the chief financial officer, will report directly to Mr So.\"\n",
      "sB = \"Current Chief Operating Officer Mike Butcher and Group Chief Financial Officer Alex Arena will report to So.\"\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "count_v = CountVectorizer()\n",
      "tdm = count_v.fit_transform([sA, sB])\n",
      "A = tdm[0]\n",
      "B = tdm[1]\n",
      "print(type(A))\n",
      "print(type(B))\n",
      "\n",
      "print (type(B),B.shape,A.shape)\n",
      "#pairwise_distances_argmin_min(A,Bp,axis=1,metric='jaccard')\n",
      "Bp = B.toarray()\n",
      "Ap = A.toarray()\n",
      "print (type(Bp))\n",
      "print (Bp)\n",
      "print (Ap)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'scipy.sparse.csr.csr_matrix'>\n",
        "<class 'scipy.sparse.csr.csr_matrix'>\n",
        "<class 'scipy.sparse.csr.csr_matrix'> (1, 11) (1, 11)\n",
        "<class 'numpy.ndarray'>\n",
        "[[1 1 0 1 1 1 1 1 0 0 1]]\n",
        "[[1 0 1 1 0 0 1 0 1 1 1]]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 2 Padding Vectors to Make Iquals\n",
      "\n",
      "Leer esto s\u00ed se obtienen los vectores por v\u00edas diferentes y no por la v\u00eda mostrada en el paso anterior.\n",
      "Las distancias vectoriales solo funcionan si estos tienen las mismas longitudes.\n",
      "Dos cadenas de textos (Ej. oraciones) pueden ser totalmente diferentes.\n",
      "Es necesario igualar estos vectores."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([0,1,0,0,1,1,1,0,0,1,0,0,0,0],dtype=np.int32)\n",
      "B = np.array([0,0,1,0,1,0,1,0,1],dtype=np.int32)\n",
      "\n",
      "Bp = np.pad(B,(0,len(A)-len(B)),'constant') #padding B with value 0 constant at the right side to the A len."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 3 Calculate Similarities"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy\n",
      "import sklearn\n",
      "from sklearn.metrics.pairwise import *\n",
      "\n",
      "#Reshape the vectos to samples,features\n",
      "#Bp = Bp.reshape(1,-1)\n",
      "#A = A.reshape(1,-1)\n",
      "\n",
      "# jaccard similarity\n",
      "pairwise_distances_argmin_min(Ap,Bp,axis=1,metric='jaccard')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 105,
       "text": [
        "(array([0]), array([ 0.63636364]))"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The result is correct by hand computation."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 4 Construct a Vector of Features\n",
      "\n",
      "En este paso se deben calcular varias medidas de similitud y construir un vector con ellas.\n",
      "\n",
      "    pairwise_distances_argmin_min(A,Bp,axis=1,metric='dice')\n",
      "    pairwise_distances_argmin_min(A,Bp,axis=1,metric='hamming')\n",
      "    pairwise_distances_argmin_min(A,Bp,axis=1,metric='cityblock')\n",
      "    pairwise_distances_argmin_min(A,Bp,axis=1,metric='cosine')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics.pairwise import * #support sparse matrix inputs\n",
      "from scipy.spatial.distance import * #do not support sparse matrix inputs\n",
      "\n",
      "#Use the next line if your vectors have more than 14 samples, the 'mahalanobis' distance fail\n",
      "    #from sklearn.metrics.pairwise import _VALID_METRICS \n",
      "\n",
      "_VALID_METRICS = ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock',\n",
      "                  'braycurtis', 'canberra', 'chebyshev', 'correlation',\n",
      "                  'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski',\n",
      "                  'matching', 'minkowski', 'rogerstanimoto',\n",
      "                  'russellrao', 'seuclidean', 'sokalmichener',\n",
      "                  'sokalsneath', 'sqeuclidean', 'yule',]\n",
      "vector = []\n",
      "\n",
      "for distance in _VALID_METRICS:\n",
      "    index, dist =  pairwise_distances_argmin_min(A,Bp, axis=1, metric=distance)\n",
      "    vector.append(dist[0])\n",
      "\n",
      "_DISTANCE_VECTOR = np.array(vector, dtype = np.float16)\n",
      "_DISTANCE_VECTOR = _DISTANCE_VECTOR.reshape(1,-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (_DISTANCE_VECTOR.shape)\n",
      "print (_DISTANCE_VECTOR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1, 23)\n",
        "[[ 2.23632812  2.23632812  5.          5.          5.          0.55566406\n",
        "   5.          1.          0.81152344  0.55273438  0.55566406  0.35717773\n",
        "   0.71435547  0.89453125  0.35717773  2.23632812  0.52636719  0.85693359\n",
        "          inf  0.52636719  0.83349609  5.          0.60009766]]\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 5 Scale all Features for Normalization\n",
      "\n",
      "Todas las caracter\u00edsticas deber\u00e1s ser llevadas en el intervalo [0,1].\n",
      "En nuestro caso se utilizar\u00e1 una clase que utiliza el mayor valor valor existente en cualquiera de los features para\n",
      "tomar como 1. Existen otras t\u00e9cnicas que pueden ser estudiadas en el m\u00f3dulo sklearn.preprocessing.\n",
      "\n",
      "    from sklearn.preprocessing import MaxAbsScaler\n",
      "\n",
      "    maxabs = MaxAbsScaler()\n",
      "    _DISTANCE_VECTOR_NORM = maxabs.fit_transform(_DISTANCE_VECTOR)\n",
      "    \n",
      "Este m\u00e9todo tiene el inconveniente de que necesita varias muestras. Por lo tanto vamos a usar una muestra extraida de un fichero\n",
      "ARFF."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.io import arff\n",
      "import pandas as pd\n",
      "\n",
      "data, meta = arff.loadarff('msr_paraphrase_test.arff')\n",
      "\n",
      "print(data.shape) # see a (1725,) is important to reduce this for this notebook\n",
      "\n",
      "#Reduce the samples\n",
      "_DISTANCE_MATRIX_a = data[:10] # This matrix contain non numeric values, is important to drop\n",
      "\n",
      "# Using pandas to worki with the distance matrix\n",
      "_DISTANCE_MATRIX_b = pd.DataFrame(_DISTANCE_MATRIX_a)\n",
      "_DISTANCE_MATRIX_c = _DISTANCE_MATRIX_b.drop(['class'], axis=1)\n",
      "\n",
      "from sklearn.preprocessing import MaxAbsScaler\n",
      "\n",
      "maxabs = MaxAbsScaler()\n",
      "_DISTANCE_MATRIX_NORM = maxabs.fit_transform(_DISTANCE_MATRIX_c)\n",
      "print('original MATRIX[0]\\n', _DISTANCE_MATRIX_a[0],'\\ntype',_DISTANCE_MATRIX_a.dtype, 'shape',_DISTANCE_MATRIX_a.shape,'\\n')\n",
      "print('transformed MATRIX[0]\\n', _DISTANCE_MATRIX_NORM[0],'\\ntype',_DISTANCE_MATRIX_NORM.dtype, 'shape',_DISTANCE_MATRIX_NORM.shape)\n",
      "\n",
      "#Converting the result in a DataFrame\n",
      "_NormMatrix_DataFrame = pd.DataFrame(_DISTANCE_MATRIX_NORM,columns=_DISTANCE_MATRIX_c.columns)\n",
      "print(_NormMatrix_DataFrame.columns)\n",
      "print(_NormMatrix_DataFrame.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1725,)\n",
        "original MATRIX[0]\n",
        " (0.7250000238418579, 0.4859813153743744, 0.6168224215507507, 0.6168224215507507, 0.7393431663513184, 0.7393431663513184, 0.9111268520355225, 0.8916666507720947, 0.5800865888595581, 0.3888888955116272, 0.43835699558258057, 0.4375, 0.7851654887199402, 0.2800000011920929, 0.3684210479259491, 0.8577276468276978, 0.46666666865348816, 0.5833333730697632, b'yes') \n",
        "type [('NeedlemanWunch', '<f8'), ('SmithWaterman', '<f8'), ('SmithWatermanGotoh', '<f8'), ('SmithWatermanGotohWindowedAffine', '<f8'), ('Jaro', '<f8'), ('JaroWinkler', '<f8'), ('ChapmanMeanLength', '<f8'), ('ChapmanLengthDeviation', '<f8'), ('QGramsDistance', '<f8'), ('BlockDistance', '<f8'), ('CosineSimilarity', '<f8'), ('DiceSimilarity', '<f8'), ('EuclideanDistance', '<f8'), ('JaccardSimilarity', '<f8'), ('MatchingCoefficient', '<f8'), ('MongeElkan', '<f8'), ('OverlapCoefficien', '<f8'), ('Levenshtein', '<f8'), ('class', 'S3')] shape (10,) \n",
        "\n",
        "transformed MATRIX[0]\n",
        " [ 0.88359377  0.55277496  0.67167594  0.67167594  0.88752249  0.79225245\n",
        "  0.9220618   0.91024303  0.72510823  0.49122807  0.54455337  0.54687499\n",
        "  0.86514849  0.41999999  0.49736843  0.913556    0.51851853  0.77777783] \n",
        "type float64 shape (10, 18)\n",
        "Index(['NeedlemanWunch', 'SmithWaterman', 'SmithWatermanGotoh',\n",
        "       'SmithWatermanGotohWindowedAffine', 'Jaro', 'JaroWinkler',\n",
        "       'ChapmanMeanLength', 'ChapmanLengthDeviation', 'QGramsDistance',\n",
        "       'BlockDistance', 'CosineSimilarity', 'DiceSimilarity',\n",
        "       'EuclideanDistance', 'JaccardSimilarity', 'MatchingCoefficient',\n",
        "       'MongeElkan', 'OverlapCoefficien', 'Levenshtein'],\n",
        "      dtype='object')\n",
        "(10, 18)\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Extra Example\n",
      "\n",
      "Experimento con las letras, para descartar el uso de medidas basadas en caracteres."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sA = \"Pedro com\u00eda arroz a la orilla del r\u00edo\"\n",
      "sB = \"Jos\u00e9 come arroz en la ladera del r\u00edo\"\n",
      "\n",
      "A = list(sA)\n",
      "B = list(sB)\n",
      "\n",
      "print(A)\n",
      "print(type(B))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['P', 'e', 'd', 'r', 'o', ' ', 'c', 'o', 'm', '\u00ed', 'a', ' ', 'a', 'r', 'r', 'o', 'z', ' ', 'a', ' ', 'l', 'a', ' ', 'o', 'r', 'i', 'l', 'l', 'a', ' ', 'd', 'e', 'l', ' ', 'r', '\u00ed', 'o']\n",
        "<class 'list'>\n"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Es imposible utilizar este m\u00e9todo del **CountVectorizer** para cadenas de caracteres.\n",
      "\n",
      "# Conclusiones\n",
      "\n",
      "Este el *sklearn.metrics.pairwise* m\u00e9todo permite obtener 23 medidas basadas en t\u00e9rminos. Y no es posible utilizarlos para\n",
      "sustituir medidas basadas en caracteres. Que a priori se deber\u00eda decir deben ser menos eficaces para calcular similitud entre\n",
      "oraciones."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}