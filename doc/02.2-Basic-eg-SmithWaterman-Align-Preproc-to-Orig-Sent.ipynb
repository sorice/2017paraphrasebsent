{
 "metadata": {
  "name": "",
  "signature": "sha256:95489aaef27bb36f876d8b12d8f1eea9a14173f89f7def025c4a683e9cd2237e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Encontrando los L\u00edmites Originales de Oraciones Preprocesadas\n",
      "\n",
      "Dado un texto inicial que puede provenir de un conversor de PDF a TXT con m\u00faltiples errores.\n",
      "Este se procesa y las oraciones son convertidas a nuevas oraciones despojadas de estos errores.\n",
      "\u00bfC\u00f3mo retornar las posiciones originales de estas oraciones y su contenido original una vez \n",
      "obtenidas los l\u00edmites exactos tras el procesamiento?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('/home/abelm')\n",
      "PATH = '/home/abelm/preprocess/test/'\n",
      "\n",
      "import preprocess\n",
      "from preprocess.methods import add_text_end_dot"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Abrimos el fichero para hacer las pruebas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = open('/home/abelm/preprocess/test/test_text.txt').read()\n",
      "print (text[:round(len(text)/4)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For other (optional) flags of <opencv_createsamples>, see the official... documentation\n",
        "at http://Docs.opencv.org/doc/user_guide/ug_traincascade.html.\n",
        "[ 99 ]\n",
        "www.it-ebooks.info.\n",
        "Generating Haar Cascades for Custom 8.4 Targets\n",
        "Creating <cascade> by running:\n",
        "<opencv_traincascade>\n",
        "3. anoche.\n",
        "4 Despu\u00e9s. . . \n",
        "\n",
        "Over 110 recipes to master this full-stack Python web\n",
        "framework\n",
        "1\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** el mismo texto analizado manualmente **: \n",
      "Mostremos por un instante el mismo texto con un an\u00e1lisis hecho a mano de las oraciones."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "texth = open('/home/abelm/preprocess/test/test_text_human_analysis.txt').read()\n",
      "print (text[:round(len(text)/4)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For other (optional) flags of <opencv_createsamples>, see the official... documentation\n",
        "at http://Docs.opencv.org/doc/user_guide/ug_traincascade.html.\n",
        "[ 99 ]\n",
        "www.it-ebooks.info.\n",
        "Generating Haar Cascades for Custom 8.4 Targets\n",
        "Creating <cascade> by running:\n",
        "<opencv_traincascade>\n",
        "3. anoche.\n",
        "4 Despu\u00e9s. . . \n",
        "\n",
        "Over 110 recipes to master this full-stack Python web\n",
        "framework\n",
        "1\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Primera Funci\u00f3n\n",
      "\n",
      "La primera funci\u00f3n creada para estos fines por m\u00ed, fue para el PAN 2014, donde desafortunadamente no pude participar por\n",
      "no haber Wifi o pol\u00edticas de SSH en la UCLV que me permitieran contectarme a la PC virtual del evento. Veamos!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_sentences(text,orig_text):\n",
      "    \"\"\" Tokeniz a given text and return a dict containing all start and \n",
      "    end positions for each sentence.\n",
      "\n",
      "    :param text: generated text from clean_punctuation function.\n",
      "    :param type: string\n",
      "    :param orig_text: original text in process.\n",
      "    :param type: string\n",
      "    \n",
      "    :returns sentence_list: contain the sentence' number, the \n",
      "    generated sentence(only letters, '_' and the end-points), the \n",
      "    init-position of the original sentence equivalent to the \"generated\n",
      "    sentence\", and the end-position of the original sentence equivalent to the \"generated sentence\".\n",
      "    :rtype: tuple list.\n",
      "    \n",
      "    .. author: Abel Meneses abad\n",
      "    Finish on Fri, 28 Feb 2014\n",
      "    Next_revision on Sun Aug 3 2014\n",
      "    \"\"\"\n",
      "    sentence_list = []\n",
      "    sentence_count = 0\n",
      "    init, end = 0, 0\n",
      "\n",
      "    for i in range(len(text)):\n",
      "        if text[i] == '.':  #if '.' is found \n",
      "            end = i         #end sentence = '.' pos\n",
      "            while text[end] not in LETTERS: # in spite of found the last letter sentence pos\n",
      "                end-=1 \n",
      "            sentence = text[init:end+1]     # then construct exactly the sentence without end '.'\n",
      "            tuple = (sentence_count,sentence,init,end+1)\n",
      "            sentence_list.append(tuple)\n",
      "            sentence_count += 1\n",
      "            init = i\n",
      "            restante = text[init:]\n",
      "\n",
      "        elif init < len(text) and text[init] not in LETTERS:\n",
      "            init+=1\n",
      "            restante = text[init:]\n",
      "\n",
      "    count = 0\n",
      "    words = []\n",
      "    new_origen = 0\n",
      "    len_quitadas = 0\n",
      "    orig_text2 = orig_text\n",
      "    sentence_list2 = []\n",
      "    for i in range(len(sentence_list)):\n",
      "        oracion_buscada = sentence_list[i][1]\n",
      "        for word in oracion_buscada.split():\n",
      "            words.append(word)\n",
      "\n",
      "        lengt_oracion_buscada = len(oracion_buscada)\n",
      "        new_origen = orig_text.find(words[0])\n",
      "        orig_pos_init = new_origen + len_quitadas   #D\u00f3nde aparece la primera palabra de la oraci\u00f3n que estoy buscando.\n",
      "        orig_pos_end = orig_pos_init + lengt_oracion_buscada # Posici\u00f3n inicial + largo de la oraci\u00f3n = posici\u00f3n final.\n",
      "\n",
      "        tuple = (i, oracion_buscada, orig_pos_init, orig_pos_end) #construye la tupla con los valores del doc original.\n",
      "        sentence_list2.append(tuple)\n",
      "        restante = orig_text[new_origen+lengt_oracion_buscada:] # Elimino del texto la oraci\u00f3n encontrada, queda de primera la siguiente\n",
      "\n",
      "        orig_text = orig_text[new_origen+lengt_oracion_buscada:]    # Elimino del texto la oraci\u00f3n encontrada, queda de primera la siguiente\n",
      "        len_quitadas = orig_pos_end\n",
      "        words = []\n",
      "\n",
      "    sentence_list = sentence_list2\n",
      "\n",
      "    return sentence_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Probando"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import string\n",
      "LETTERS = ''.join([string.ascii_letters,string.digits,'\u00f1\u00d1\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc'])\n",
      "textr = open('/home/abelm/preprocess/test/test_text_result.txt').read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Comprobando\n",
      "sentenceList = find_sentences(textr,text)\n",
      "print (sentenceList[0][1])\n",
      "print (text[sentenceList[0][2]:sentenceList[0][3]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For other optional flags of opencv_createsamples see the official documentation at http___Docs_opencv_org_doc_user_guide_ug_traincascade_html\n",
        "For other (optional) flags of <opencv_createsamples>, see the official... documentation\n",
        "at http://Docs.opencv.org/doc/user_guide/ug_traincasc\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Resultado\n",
      "\n",
      "Como ven suele fallar, as\u00ed que vamos a probar una versi\u00f3n utilizando el algoritmo de Smith-Waterman de alineamiento de textos. Tambi\u00e9n usado en las medidas de similitud de cadenas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import swalign\n",
      "# choose your own values here\u2026 2 and -1 are common.\n",
      "match = 2\n",
      "mismatch = -1\n",
      "scoring = swalign.NucleotideScoringMatrix(match, mismatch)\n",
      "\n",
      "sw = swalign.LocalAlignment(scoring)  # you can also choose gap penalties, etc...\n",
      "alignment = sw.align('ACACACTA','AGCACACA')\n",
      "alignment.dump()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Query: 1 AGCACAC-A 8\n",
        "         | ||||| |\n",
        "Ref  : 1 A-CACACTA 8\n",
        "\n",
        "Score: 12\n",
        "Matches: 7 (77.8%)\n",
        "Mismatches: 2\n",
        "CIGAR: 1M1I5M1D1M\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Probemos un ejemplo real con nuestros textos.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textr = open('/home/abelm/preprocess/test/test_text_result.txt').read()\n",
      "s1 = textr[:143]\n",
      "text = open('/home/abelm/preprocess/test/test_text.txt').read()\n",
      "s2 = text[:]\n",
      "s2 = s2.replace('\\n',' ')\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Query:   1 For other (optional) flags of <opencv_createsamples>, see the official... documentation at http://Docs.opencv.org/doc/user_guide/ug_traincascade.html.  151\n",
        "           |||||||||| |||||||| |||||||||| ||||||||||||||||||||  |||||||||||||||||   ||||||||||||||||||||||...||||.||||||.|||.|||.||||||||||.|||||||||||||||.|||| |\n",
        "Ref  :   1 For other -optional- flags of -opencv_createsamples-- see the official--- documentation at http___Docs_opencv_org_doc_user_guide_ug_traincascade_html-  142\n",
        "\n",
        "Score: 248\n",
        "Matches: 133 (88.1%)\n",
        "Mismatches: 18\n",
        "CIGAR: 10M1I8M1I10M1I20M2I17M3I76M1I1M\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Como se puede ver utilizando los puntos que existen en la primera oraci\u00f3n (71, 72, 73, 103, 110, 145 y 150) la similitud con\n",
      "la oraci\u00f3n preprocesada va desde 92% al 88%.\n",
      "Si utilizamos el texto completo la funci\u00f3n encuentra la porci\u00f3n donde hay mayor coincidencia. En el ejemplo mostrado se nota que el **Query** desde 1 hasta 151 es la oraci\u00f3n buscada.\n",
      "\n",
      "Note al correr esta celda que para textos grandes esto podr\u00eda demorar.\n",
      "Utilicemos un ardid surgido de la experimentaci\u00f3n: buscar el punto inicial(que es el 0 o el \u00faltimo punto de la oraci\u00f3n anterior\n",
      "encontrada), y utilicemos el tama\u00f1o de **s1** para comparar el fragmento final de s1 con cualquiera del mismo tama\u00f1o \n",
      "desde donde quiera que encuentro un punto en **s2** (71, 72, 73, 103, 110, 145 y 150), hacia atr\u00e1s."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cut(string,num, w):\n",
      "    \"\"\"Funci\u00f3n auxiliar para cortar un texto dada un intervalo [w,num]\n",
      "    Solo sirve para el pr\u00f3ximo bloque. No se usa en el algoritmo final\n",
      "    aunque s\u00ed se us\u00f3 la idea de cortar para reducir los tiempos de c\u00f3mputo.\n",
      "    \"\"\"\n",
      "    stri = string[:num]\n",
      "    stri = stri.replace('\\n',' ')\n",
      "    strig = stri[-round(w/4):]\n",
      "    return strig"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "N\u00f3tese que en el bloque siguiente los puntos finales (71, 72,...) fueron calculados manualmente para poder analizar que ocurr\u00eda.\n",
      "Este ser\u00eda el procedimiento normal durante una investigaci\u00f3n.\n",
      "En el algoritmo final estas posiciones se calculan autom\u00e1ticamente al detectar cada posici\u00f3n de un punto."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textr = open('/home/abelm/preprocess/test/test_text_result.txt').read()\n",
      "sr = textr[:143]\n",
      "w = len(sr)\n",
      "s1 = sr[-round(w/4):]\n",
      "text = open('/home/abelm/preprocess/test/test_text.txt').read()\n",
      "s2 = cut(text,71,w)\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump();print(71)\n",
      "s2 = cut(text,72,w)\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump();print(72)\n",
      "s2 = cut(text,73,w)\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump();print(73)\n",
      "s2 = cut(text,103,w)\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump();print(103)\n",
      "s2 = cut(text,110,w)\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump();print(110)\n",
      "s2 = cut(text,145,w)\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump();print(145)\n",
      "print (s1,'\\n',s2,'\\n****************')\n",
      "s2 = cut(text,150,w)\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump();print(150)\n",
      "print (s1,'\\n',s2,'\\n****************')\n",
      "s2 = cut(text,162,w)\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump();print(162)\n",
      "print (s1,'\\n',s2,'\\n****************')\n",
      "s2 = cut(text,172,w)\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump();print(172)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Query: 31 i-cia 34\n",
        "          | | |\n",
        "Ref  : 21 inc-a 24\n",
        "\n",
        "Score: 4\n",
        "Matches: 3 (60.0%)\n",
        "Mismatches: 2\n",
        "CIGAR: 1M1D1M1I1M\n",
        "71\n",
        "Query: 30 i-cia 33\n",
        "          | | |\n",
        "Ref  : 21 inc-a 24\n",
        "\n",
        "Score: 4\n",
        "Matches: 3 (60.0%)\n",
        "Mismatches: 2\n",
        "CIGAR: 1M1D1M1I1M\n",
        "72\n",
        "Query: 29 i-cia 32\n",
        "          | | |\n",
        "Ref  : 21 inc-a 24\n",
        "\n",
        "Score: 4\n",
        "Matches: 3 (60.0%)\n",
        "Mismatches: 2\n",
        "CIGAR: 1M1D1M1I1M\n",
        "73\n",
        "Query: 15 t-ation a 22\n",
        "          | | | |.|\n",
        "Ref  : 18 tra-i-nca 24\n",
        "\n",
        "Score: 6\n",
        "Matches: 5 (55.6%)\n",
        "Mismatches: 4\n",
        "CIGAR: 1M1D1M1I1M1I3M\n",
        "103\n",
        "Query:  8 t-ation a 15\n",
        "          | | | |.|\n",
        "Ref  : 18 tra-i-nca 24\n",
        "\n",
        "Score: 6\n",
        "Matches: 5 (55.6%)\n",
        "Mismatches: 4\n",
        "CIGAR: 1M1D1M1I1M1I3M\n",
        "110\n",
        "Query:  7 oc/user_guide/ug_traincascade 35\n",
        "          ||.||||||||||.|||||||||||||||\n",
        "Ref  :  1 oc_user_guide_ug_traincascade 29\n",
        "\n",
        "Score: 52\n",
        "Matches: 27 (93.1%)\n",
        "Mismatches: 2\n",
        "CIGAR: 29M\n",
        "145\n",
        "oc_user_guide_ug_traincascade_html . \n",
        " .org/doc/user_guide/ug_traincascade. \n",
        "****************\n",
        "Query:  2 oc/user_guide/ug_traincascade.html-. 36\n",
        "          ||.||||||||||.|||||||||||||||.|||| |\n",
        "Ref  :  1 oc_user_guide_ug_traincascade_html . 36\n",
        "\n",
        "Score: 60\n",
        "Matches: 32 (88.9%)\n",
        "Mismatches: 4\n",
        "CIGAR: 34M1D1M\n",
        "150\n",
        "oc_user_guide_ug_traincascade_html . \n",
        " doc/user_guide/ug_traincascade.html. \n",
        "****************\n",
        "Query:  1 de/ug_traincascade.html.  25\n",
        "          ||.|||||||||||||||.|||| |\n",
        "Ref  : 12 de_ug_traincascade_html-  35\n",
        "\n",
        "Score: 41\n",
        "Matches: 22 (88.0%)\n",
        "Mismatches: 3\n",
        "CIGAR: 23M1I1M\n",
        "162\n",
        "oc_user_guide_ug_traincascade_html . \n",
        " de/ug_traincascade.html. [ 99 ] www. \n",
        "****************\n",
        "Query:  1 ncascade.html.  15\n",
        "          ||||||||.|||| |\n",
        "Ref  : 22 ncascade_html-  35\n",
        "\n",
        "Score: 24\n",
        "Matches: 13 (86.7%)\n",
        "Mismatches: 2\n",
        "CIGAR: 13M1I1M\n",
        "172\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textr = open('/home/abelm/preprocess/test/test_text_result.txt').read()\n",
      "sr = textr[144:167]\n",
      "w = len(sr)\n",
      "s1 = sr[-round(w/4):]\n",
      "text2 = open('/home/abelm/preprocess/test/test_text.txt').read()\n",
      "text = text2[151:217]\n",
      "s2 = cut(text,11,w)\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump();print(11)\n",
      "print (s1,'\\n',s2,'\\n****************')\n",
      "s2 = cut(text,21,w)\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump();print(21)\n",
      "print (s1,'\\n',s2,'\\n****************')\n",
      "s2 = cut(text,26,w)\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump();print(26)\n",
      "print (s1,'\\n',s2,'\\n****************')\n",
      "s2 = cut(text,65,w)\n",
      "alignment = sw.align(s1,s2)\n",
      "alignment.dump();print(65)\n",
      "print (s1,'\\n',s2,'\\n****************')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Query: 6 . 6\n",
        "         |\n",
        "Ref  : 6 . 6\n",
        "\n",
        "Score: 2\n",
        "Matches: 1 (100.0%)\n",
        "Mismatches: 0\n",
        "CIGAR: 1M\n",
        "11\n",
        "info . \n",
        " ] www. \n",
        "****************\n",
        "Query: 6 . 6\n",
        "         |\n",
        "Ref  : 6 . 6\n",
        "\n",
        "Score: 2\n",
        "Matches: 1 (100.0%)\n",
        "Mismatches: 0\n",
        "CIGAR: 1M\n",
        "21\n",
        "info . \n",
        " books. \n",
        "****************\n",
        "Query: 2 info-. 6\n",
        "         |||| |\n",
        "Ref  : 1 info . 6\n",
        "\n",
        "Score: 9\n",
        "Matches: 5 (83.3%)\n",
        "Mismatches: 1\n",
        "CIGAR: 4M1D1M\n",
        "26\n",
        "info . \n",
        " .info. \n",
        "****************\n",
        "Query: 2 om 8. 6\n",
        "         | | |\n",
        "Ref  : 4 o- -. 6\n",
        "\n",
        "Score: 4\n",
        "Matches: 3 (60.0%)\n",
        "Mismatches: 2\n",
        "CIGAR: 1M1I1M1I1M\n",
        "65\n",
        "info . \n",
        " tom 8. \n",
        "****************\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Conclusiones parciales\n",
      "\n",
      "Como se puede observar en ambos ejemplos el mayor score lo da en la posici\u00f3n donde coincide el punto final de la oraci\u00f3n\n",
      "de la que fue editada.\n",
      "Y el experimento de medir la distancia desde un cuarto de la oraci\u00f3n hasta el final ofrece mayor velocidad.\n",
      "Implementemos ahora el algoritmo final."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}