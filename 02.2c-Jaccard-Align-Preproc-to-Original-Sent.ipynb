{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>This notebook was put together by [Abel Meneses-Abad](http://www.menesesabad.com) for SciPy LA Habana 2017. Source and license info is on [github repository](http://github.com/sorice/simtext_scipyla2017).</i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Alignment Algorithm Phase\n",
    "\n",
    "The objective of this phase is to get a <font color='#FA0000'>new text structure</font> with normalized sentences and its original related by the offset and length properties. E.g.:\n",
    "\n",
    "<a id='Aligned_Text_Structure'></a>\n",
    "<font color='#FA0000'>**Aligned Text Structure:**</font>\n",
    "If you open a the abstract-name file *suspicious-document00XYZ.txt*, then you would get a text with de following structure in every line:\n",
    "\n",
    "<p><font color='#FA0000'>\n",
    "   $(id_K,normalized-sentence_K,original\\,offset_{sentence\\,K},original\\,offset+length_{sentence\\,K})$\n",
    "   </font>\n",
    "\n",
    "*Why we need this?*\n",
    "This is useful for example when you are working in a real plagiarism detection or text-reuse detection applications and you need to show to the users the similarity result between the preprocessed fragments or sentences and its original form (pdf, html, etc). Additionally is very safe to work with duplicated or transformed objects very well related to the originals, after have them you can do subsequent transformations to the copy-object and never loss the original length and position of this sentence or fragment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment Algorithm based on Jaccard Distance\n",
    "\n",
    "The final algorithm needs 4 auxiliar functions:\n",
    "\n",
    "1. A character replacement function in the original text in which Smith-Waterman fails (*Eg: line breaks*) (**normalize**)\n",
    "2. A function to look over the list of sentences of the preproces text (**getSentA**).\n",
    "3. A function to look over the list of segments of the original-text ending with '.'(**getSentB**).\n",
    "4. Jaccard function to validate Smith-Watermna alignment (**Jaccard**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import cell\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Text Normalization Function\n",
    "\n",
    "To improve the precision of Jaccard algorithm is necessary to convert some punctuation situation.\n",
    "The main feature here is that whole regular expressions and functiones used does not change the length of the original text. The [previous](02.1-Normalizing-Text-Corpus.ipynb) normalization process it doest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/abelm')\n",
    "from preprocess.methods import add_text_end_dot, abbrev_recognition_support, del_contiguous_point_support \n",
    "from preprocess.methods import contiguos_string_recognition_support\n",
    "\n",
    "def normalize(text_orig):\n",
    "    replacement_patterns = [(r'[:](?=\\s*?\\n)','##1'),\n",
    "                            (r'\\xc2|\\xa0',' '),\n",
    "                            (r'(\\w\\s*?):(?=\\s+?[A-Z]+?)|(\\w\\s*?):(?=\\s*?\"+?[A-Z]+?)','\\g<1>##2'),\n",
    "                            (r'[?!]','##3'),\n",
    "                            (r'(\\w+?)(\\n)(?=[\"$%()*+&,-/;:¿¡<=>@[\\\\]^`{|}~\\t\\s]*(?=.*[A-Z0-9]))','\\g<1>##4'), # any alphanumeric char\n",
    "                            # follow by \\n follow by any number of point sign follow by a capital letter, replace by alphanumerig+.\n",
    "                            (r'(\\w+?)(\\n)(?=[\"$%()*+&,-/;:¿¡<=>@[\\\\]^`{|}~\\t\\s\\n]*(?=[a-zA-Z0-9]))','\\g<1>##5'),# any alphanumeric char\n",
    "                            # follow by \\n follow by any number of point sign follow by a letter, replace by alphanumerig+.\n",
    "                            (r'[:](?=\\s*?)(?=[\"$%()*+&,-/;:¿¡<=>@[\\\\]^`{|}~\\t\\s]*[A-Z]+?)','##6'),\n",
    "                            (r'(\\w+?\\s*?)\\|','\\g<1>##7'),\n",
    "                            (r'\\n(?=\\s*?[A-Z]+?)','##8'),\n",
    "                            (r'##\\d','apdbx'),\n",
    "                            ]\n",
    "    \n",
    "    for (pattern, repl) in replacement_patterns:\n",
    "            (text_orig, count) = re.subn(pattern, repl, text_orig)\n",
    "    \n",
    "    text_orig = del_contiguous_point_support(text_orig)\n",
    "    text_orig = contiguos_string_recognition_support(text_orig)\n",
    "    text_orig = abbrev_recognition_support(text_orig)\n",
    "    text_orig = re.sub(r'apdbx+','.', text_orig)\n",
    "    text_orig = add_text_end_dot(text_orig)#append . final si el último caracter no tiene punto, evita un ciclo infinito al final.\n",
    "    return text_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sentence A\n",
    "\n",
    "Get all sentences in preprocessed text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentA(text):\n",
    "    offset = 0\n",
    "    for i in re.finditer('\\.',text):\n",
    "        sentA = text[offset:i.end()]\n",
    "        yield sentA, offset, i.end()\n",
    "        offset = i.end()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The is a 5 acre 20 000 m located in the of located in . 0 55\n",
      "1 The zoo is operated by the in partnership with the . 56 108\n",
      "2 Queens Zoo zoo New York City borough Queens Flushing Meadows_Corona Park Wildlife Conservation Society New York City Department of Parks and Recreation . 109 262\n",
      "3 The Zoo opened on with the ceremonial ribbon cut by . 263 316\n",
      "4 The zoo is home mostly to animals native to North America . 317 376\n",
      "5 The Queens Zoo is the only one of the five zoos in New York City to exhibit . 377 454\n",
      "6 The zoo was constructed on the site of the and the zoo is aviary is a designed by and used during the 1964 Fair . 455 568\n",
      "7 October 26 1968 Robert Moses 2 Spectacled Bears 1964 New York World is Fair geodesic dome Buckminster Fuller 1  . 569 682\n"
     ]
    }
   ],
   "source": [
    "#Example of getSentA use\n",
    "preprocessed_text = open('../norm/susp/suspicious-document00184.txt').read()\n",
    "        \n",
    "for i,(sentA, offset, length) in enumerate(getSentA(preprocessed_text)):\n",
    "    print (i,sentA, offset, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sentence B\n",
    "\n",
    "<center><strong>Diagrama simplificado getSentB function.</strong></center></br>\n",
    "<table border=0 cellspacing=10> \n",
    "    <caption align=\"bottom\"> </br><em>Figura 2.3.1: Esquema del Algoritmo Get Sentence B</em>\n",
    "    </caption> \n",
    "<tr align=\"center\">\n",
    "    <th> <img src=\"imgs/getSentB.jpg\" height=800px width=1200px alt=\"*\" \n",
    "        align=\"center\"> </th>\n",
    "    <th> </th>\n",
    "    <td> \n",
    "        <p> El algoritmo comienza a buscar en el texto original el caracter '.'  más cercano al offsetB (*$\\|\\overrightarrow{sB}\\|=0 \\Longrightarrow sentLength = 0$*).\n",
    "        Una vez encontrado denota como punto previo este nuevo punto para una nueva llamada (*$sentLength = \\|\\overrightarrow{sB}\\|+1$*), \n",
    "        luego calcula el segmento, y define el punto siguiente como $Offset + \\|\\overrightarrow{sB}\\|$ *(len segmento definido por el . encontrado)*.\n",
    "        En la siguiente corrida el algoritmo encontrará el '.' más cercano a partir de **sB** \n",
    "        calculando el nuevo punto siguiente(*sB`*). Y así sucesivamente\n",
    "        ante cada llamada en la función *getSentB*. Es en la función de alineación donde se establece la condición \n",
    "        de parada cuando el score de Smith-Waterman es máximo entre el *$\\|\\overrightarrow{sB^{n`}}\\|$ y *length sentA*. \n",
    "        </p>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0 sentB: The is a 5 acre (20,000 m ) located in the of , located in .\n",
      "offsetB: 0 nextPoint: 60 sentLength 60\n",
      "***************\n",
      "i 1 sentB: The is a 5 acre (20,000 m ) located in the of , located in . The zoo is operated by the in partnership with the .\n",
      "offsetB: 0 nextPoint: 113 sentLength 113\n",
      "***************\n",
      "i 2 sentB: The is a 5 acre (20,000 m ) located in the of , located in . The zoo is operated by the in partnership with the .Queens Zoo zoo New York City borough Queens Flushing Meadows-Corona Park Wildlife Conservation Society New York City Department of Parks and Recreation\n",
      "The Zoo opened on , , with the ceremonial ribbon cut by .\n",
      "offsetB: 0 nextPoint: 322 sentLength 322\n",
      "***************\n",
      "i 3 sentB:  The zoo is home mostly to animals native to North America.\n",
      "offsetB: 322 nextPoint: 381 sentLength 59\n",
      "***************\n",
      "i 4 sentB:  The zoo is home mostly to animals native to North America. The Queens Zoo is the only one of the five zoos in New York City to exhibit .\n",
      "offsetB: 322 nextPoint: 459 sentLength 137\n",
      "***************\n",
      "i 5 sentB:  The zoo is home mostly to animals native to North America. The Queens Zoo is the only one of the five zoos in New York City to exhibit . The zoo was constructed on the site of the , and the zoo's aviary is a , designed by and used during the 1964 Fair.\n",
      "offsetB: 322 nextPoint: 575 sentLength 253\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "def getSentB(text2, offsetB, nextPoint,sentLength):\n",
    "    posB = text2[offsetB+sentLength:].find('.')\n",
    "    sentLength += posB+1\n",
    "    sentB = text2[offsetB:offsetB+sentLength]\n",
    "    nextPoint = offsetB + sentLength\n",
    "    return sentB, nextPoint, sentLength\n",
    "\n",
    "text_orig = open('../susp/suspicious-document00184.txt').read()\n",
    "\n",
    "offsetB = 0;nextPoint = 0;sentLength=0\n",
    "\n",
    "for i in range(text_orig.count('.')):\n",
    "    sentB, nextPoint, sentLength = getSentB(text_orig,offsetB,nextPoint,sentLength)\n",
    "    print('i',i,'sentB:',sentB)\n",
    "    print('offsetB:', offsetB, 'nextPoint:', nextPoint, 'sentLength', sentLength)\n",
    "    print('***************')\n",
    "    if i == 2: #This is a cuting point see the explanation below\n",
    "        offsetB = nextPoint\n",
    "        nextPoint = 0\n",
    "        sentLength = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** as you can prove later in the alingment algorithm, when sentA match with sentB the value of the offset parameter is equalized to *nextPoint*. Then the algorithm start to look for the next sentB from the final position (*last* **nextPoint**) of previous sentB. In the above example 322 is at the same time the las nextPoint(& len) of $sentB_1$, and the offset of $sentB_2$, this one start with the string: *The zoo is home mostly...*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Function\n",
    "\n",
    "Originally Jaccard distance is evaluated as $(A\\cup B- B\\cap A)/B\\cup A)$, which means the fraction between different labels and similar labels inside A & B sets. Here we implement a variation $Jaccard=(B\\cap A)/B\\cup A)$, which means the fraction between common terms and the total different terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(text1,text2):\n",
    "    sentA1 = re.sub(r'[!\"#$%&()\\'*+,-/:;<=>?@\\\\^_`{|}~.\\[\\]]',' ', text1)\n",
    "    sentB1 = re.sub(r'[!\"#$%&()\\'*+,-/:;<=>?@\\\\^_`{|}~.\\[\\]]',' ', text2)\n",
    "    setA = set(sentA1.split())\n",
    "    setB = set(sentB1.split())\n",
    "    if len(setA.union(setB)) == 0:\n",
    "        return 0, sentA1, sentB1\n",
    "    else:\n",
    "        return len(setA.intersection(setB))/float(len(setA.union(setB))), sentA1, sentB1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment Pipeline\n",
    "\n",
    "* The next code print jaccard score between sentence A & B. \n",
    "* Then print the maximal score finded for a chunck B given sentence A. \n",
    "* Next the main properties of chunck B (offset & length) are printed. \n",
    "* Finally for a visual comparation of result sentence A is printed.\n",
    "\n",
    "**Nota:** To see more details about how process occurs uncomment the *print* orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard_measure: 1.0\n",
      "#############RESULTADO de la ORACIÓN : 1\n",
      "score max: 1.0 offsetB: 37 lengthB: 52\n",
      "sentB: Alama Highway Patrol Door Seal\n",
      "681 (as of 2004) [3]\n",
      "\n",
      "sentA: Alama Highway Patrol Door Seal 681 as of 2004 3 .\n",
      "\n",
      "***************\n",
      "jaccard_measure: 1.0\n",
      "#############RESULTADO de la ORACIÓN : 2\n",
      "score max: 1.0 offsetB: 89 lengthB: 31\n",
      "sentB: Civilians\n",
      "587 (as of 2004) [4]\n",
      "\n",
      "sentA: Civilians 587 as of 2004 4 .\n",
      "\n",
      "***************\n",
      "jaccard_measure: 1.0\n",
      "#############RESULTADO de la ORACIÓN : 3\n",
      "score max: 1.0 offsetB: 120 lengthB: 17\n",
      "sentB: Agency executive\n",
      "\n",
      "sentA: Agency executive .\n",
      "\n",
      "***************\n",
      "jaccard_measure: 1.0\n",
      "#############RESULTADO de la ORACIÓN : 4\n",
      "score max: 1.0 offsetB: 137 lengthB: 36\n",
      "sentB: Major Roscoe Howell, Division Chief\n",
      "\n",
      "sentA: Major Roscoe Howell Division Chief .\n",
      "\n",
      "***************\n",
      "jaccard_measure: 1.0\n",
      "#############RESULTADO de la ORACIÓN : 5\n",
      "score max: 1.0 offsetB: 173 lengthB: 14\n",
      "sentB: Parent agency\n",
      "\n",
      "sentA: Parent agency .\n",
      "\n",
      "***************\n",
      "jaccard_measure: 0\n",
      "#############RESULTADO de la ORACIÓN : 6\n",
      "score max: 1.0 offsetB: 187 lengthB: 10\n",
      "sentB: Footnotes\n",
      "\n",
      "sentA: Footnotes .\n",
      "\n",
      "***************\n",
      "jaccard_measure: 1.0\n",
      "#############RESULTADO de la ORACIÓN : 7\n",
      "score max: 1.0 offsetB: 197 lengthB: 82\n",
      "sentB: Division of the country, over which the agency has usual operational jurisdiction.\n",
      "sentA: Division of the country over which the agency has usual operational jurisdiction .\n",
      "\n",
      "***************\n",
      "jaccard_measure: 1.0\n",
      "#############RESULTADO de la ORACIÓN : 8\n",
      "score max: 1.0 offsetB: 279 lengthB: 20\n",
      "sentB:  Divisional agency:\n",
      "\n",
      "sentA: Divisional agency .\n",
      "\n",
      "***************\n",
      "jaccard_measure: 1.0\n",
      "#############RESULTADO de la ORACIÓN : 9\n",
      "score max: 1.0 offsetB: 299 lengthB: 81\n",
      "sentB: The is a division of the and is the agency for , which has anywhere in the state.\n",
      "sentA: The is a division of the and is the agency for which has anywhere in the state .\n",
      "\n",
      "***************\n",
      "jaccard_measure: 1.0\n",
      "#############RESULTADO de la ORACIÓN : 10\n",
      "score max: 1.0 offsetB: 380 lengthB: 189\n",
      "sentB:  It was created to protect the lives, property and constitutional rights of people in Alabama.Alabama Highway Patrol Alabama Department of Public Safety highway patrol Alabama jurisdiction\n",
      "\n",
      "sentA: It was created to protect the lives property and constitutional rights of people in Alabama_Alabama Highway Patrol Alabama Department of Public Safety highway patrol Alabama jurisdiction .\n",
      "\n",
      "***************\n",
      "jaccard_measure: 1.0\n",
      "#############RESULTADO de la ORACIÓN : 11\n",
      "score max: 1.0 offsetB: 569 lengthB: 153\n",
      "sentB: In 1971, the became the first U.S. police organization to use down-sized vehicles for regular highway patrol duties when they purchased 132 AMC Javelins.\n",
      "sentA: In 1971 the became the first U_S_ police organization to use down_sized vehicles for regular highway patrol duties when they purchased 132 AMC Javelins .\n",
      "\n",
      "***************\n",
      "jaccard_measure: 1.0\n",
      "#############RESULTADO de la ORACIÓN : 12\n",
      "score max: 1.0 offsetB: 722 lengthB: 117\n",
      "sentB:  This pre-dated, among others, the Camaros and Mustangs used by other departments years later.Alabama Highway Patrol\n",
      "\n",
      "sentA: This pre_dated among others the Camaros and Mustangs used by other departments years later_Alabama Highway Patrol .\n",
      "\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def alignSentences(preproc_text, orig_text):\n",
    "    sentenceList=[]\n",
    "    offsetB = 0\n",
    "    \n",
    "    norm_orig_text = normalize(orig_text)\n",
    "    \n",
    "    #if preproc_text.count('.') > norm_orig_text.count('.'):\n",
    "    #    raise Exception(\"Preprocess Error: number of preproc periods most be less or equal than normalize original text periods.\")\n",
    "        \n",
    "    for i, (sentA, offsetA, lengthA) in enumerate(getSentA(preproc_text)):\n",
    "        maxScore =-1; score = 0\n",
    "        prevPoint = 0#len(sentA)-2\n",
    "        nextPoint = 0\n",
    "        iqualScore = 0;prevFrag='';jaccard_measure = 0; X = {()}; Y={()}\n",
    "        prev_jaccard_measure = 1.0\n",
    "        k = 0.5\n",
    "        \n",
    "        #Sí llegamos a la última oración entonces\n",
    "        if i == preproc_text.count('.')-1: \n",
    "            lengMax = len(norm_orig_text)\n",
    "            tuple = (i, sentA, offsetB, lengMax)\n",
    "            sentenceList.append(tuple)\n",
    "            break\n",
    "        \n",
    "        #Sí no es la última oración compara hasta encontrar el score max.\n",
    "        while(score >= maxScore):\n",
    "            prev_jaccard_measure = jaccard_measure; prev_setA = X; prev_setB = Y\n",
    "            lengMax = nextPoint\n",
    "            maxScore = score\n",
    "            \n",
    "            #Get sentence B and prepare it to calc distances\n",
    "            sentB, nextPoint, prevPoint = getSentB(norm_orig_text, offsetB, nextPoint, prevPoint)\n",
    "            sentB = sentB.replace('\\n',' ') #avoid some bugs on swalign function\n",
    "            \n",
    "            #Calc measures Jaccard\n",
    "            jaccard_measure, X, Y = jaccard ( sentA , sentB) #Second measure only to lookfor errors\n",
    "            score = jaccard_measure\n",
    "            \n",
    "            #if i>-1:\n",
    "            #    print ('jaccard_measure:',jaccard_measure)\n",
    "            #    print('-----offsetB',offsetB,'---- from pos', prevPoint, '-----to pos',nextPoint)\n",
    "            #    print('i:',i,'score:',score,'maxScore:',maxScore, 'matches:',matches)\n",
    "                #print('sentB:\\n',sentB)\n",
    "            #    print('frag-sentA:',sentA[-round(len(sentA)*k):],'\\nfrag-sentB:',sentB[-round(len(sentA)*k):],'\\n')\n",
    "            \n",
    "            #Repeated sentence exception src00014\n",
    "            if prevFrag == sentB[-round(len(sentA)*k):]:\n",
    "                #print ('=================Repeated sentence')\n",
    "                break\n",
    "            #keep the previous fragment to know if the next sent is the same as before. \n",
    "            #The algh move forward to the next sentence.\n",
    "            prevFrag = sentB[-round(len(sentA)*k):] \n",
    "            \n",
    "            #Short sentence exceptions\n",
    "            if len(sentA) < 14:\n",
    "                maxScore = score\n",
    "                lengMax = nextPoint\n",
    "                break\n",
    "                \n",
    "            #Infinite loop exception\n",
    "            if score == maxScore:\n",
    "                iqualScore += 1\n",
    "            if iqualScore == 20:\n",
    "                break\n",
    "            \n",
    "        tuple = (i, sentA, offsetB, lengMax)\n",
    "        sentenceList.append(tuple)\n",
    "        \n",
    "        if i > 0:\n",
    "            print ('jaccard_measure:',prev_jaccard_measure)\n",
    "            #print (prev_setA,'<--->',prev_setB)\n",
    "            print('#############RESULTADO de la ORACIÓN :', i)\n",
    "            print('score max:',maxScore, 'offsetB:', offsetB, 'lengthB:',lengMax-offsetB)\n",
    "            print('sentB:',text_orig[offsetB:lengMax])\n",
    "            print('sentA:',sentA)\n",
    "            print('\\n***************')\n",
    "        \n",
    "        offsetB = lengMax\n",
    "\n",
    "    return sentenceList\n",
    "\n",
    "text_orig = open('../susp/suspicious-document00017.txt').read()\n",
    "preproc_text = open('../norm/susp/suspicious-document00017.txt').read()\n",
    "\n",
    "sentenceList = alignSentences(preproc_text,text_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Alignment result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oración preprocesada: The is a 5 acre 20 000 m located in the of located in .\n",
      "oración original: The is a 5 acre (20,000 m ) located in the of , located in .\n"
     ]
    }
   ],
   "source": [
    "print ('oración preprocesada:', sentenceList[0][1])\n",
    "print ('oración original:', text_orig[sentenceList[0][2]:sentenceList[0][3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Tagged Aligned Text of Whole Collection\n",
    "\n",
    "Here we have again the *file* **pairs** which contains all normalized cases, inside the normalizated collection (../norm), then we need the route to original files and finally the output directory.\n",
    "\n",
    "Rememberíng the [begining definition](#Aligned_Text_Structure) of <font color='#FA0000'>aligned text structure</font> for future phases.\n",
    "\n",
    "E.g. open the file *data/aligned/susp/suspicious-document00007.txt*\n",
    "<i>\n",
    "<p>    0\tAccording to the legend a dish was make by servants of country kings paella were let to take mixed leftovers from the large dinner home in courtly pots .\t0\t154\n",
    "<p>    1\tIt iseafood believed that the Arabic word woulderives from the paella word which means leftovers .\t154\t248\n",
    "<p>    2\tTake spanish dish guides Paella probably a a other rich .\t248\t305\n",
    "<p>    ...\n",
    "</i>\n",
    "\n",
    "$(id_K,normalized-sentence_K,original-offset_{sentence\\,K},original-length_{sentence\\,K})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 1445 TRUE: 1\n",
      "2 / 1445 TRUE: 2\n",
      "146 / 1445 TRUE: 146\n",
      "290 / 1445 TRUE: 290\n",
      "291 / 1445 TRUE: 291\n",
      "435 / 1445 TRUE: 435\n",
      "579 / 1445 TRUE: 579\n",
      "580 / 1445 TRUE: 580\n",
      "724 / 1445 TRUE: 724\n",
      "868 / 1445 TRUE: 868\n",
      "869 / 1445 TRUE: 869\n",
      "1013 / 1445 TRUE: 1013\n",
      "1157 / 1445 TRUE: 1157\n",
      "1158 / 1445 TRUE: 1158\n",
      "1302 / 1445 TRUE: 1302\n",
      "1445 / 1445 TRUE: 1445\n",
      "tiempo total:  5.598086833953857\n"
     ]
    }
   ],
   "source": [
    "%run scripts/02.3_alignNormalizedCaseList.py ../norm/norm_pairs_utils ../src/ ../susp/ ../align/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "The objective of this process was accomplished. The obtained transformed text contains the proposed structure. 1361 pairs of text (cases) were obtaibned previously from the 2000 initial normalized list using utils.py. Then we re-aligned thems to show the process of alignment using 02.3_alignNormalizedCaseList.py script.\n",
    "\n",
    "Although utils.py script use the Jaccard alignment algorithm and a 68% of the total cases were good aligned after normalization, it is very easy to test other similarity distances or alignment knowleage and obtain different results and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excersices\n",
    "\n",
    "1. The comparison between alignment text in 2.2_notebook and the algh presented here can show better performance. Implement a different alignment pipeline using another faster technique and less source code.\n",
    "\n",
    "2. Make a list of different punctuation situations that can appear in real text provided by pdftotext conversors and program the regular expresion for both sides the normalization process and for normalize function. Construct a test unit with your ideas and finally test them in the same way we did here.\n",
    "\n",
    "3. Create a different idea to align original and preprocessed sentences. Sugestion, take a look to cross-lingual alignment implemented in nltk.\n",
    "\n",
    "4. In the Smith-Waterman version of this alignment algorithm The next code can be added to the alignment pipeline to improve the alignment of long sentences. Evaluate it and propose the best k to maintain the precision.\n",
    "\n",
    "        #Optimization for very long sentences alignment\n",
    "        if len(sentA) > 500:\n",
    "            k = 0.1\n",
    "        else: k=0.5\n",
    "        \n",
    "5. The pairs list provided for this tutorial(_norm_pairs_utils_) contains 1445 cases in which the Jaccard based aligment makes a perfect score. If you test this algorithm in PAN-PC pairs file the result will be very different, some cases will be bad aligned. Make the necessary changes to the algorithm to write in the preprocessDocList file a \"False\" value if the text is bad aligned. (_Sugestion: study the utils.py file_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
