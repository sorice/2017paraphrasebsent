{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontrando los Límites Originales de Oraciones Preprocesadas\n",
    "\n",
    "Dado un texto inicial que puede provenir de un conversor de PDF a TXT con múltiples errores.\n",
    "Este se procesa y las oraciones son convertidas a nuevas oraciones despojadas de estos errores.\n",
    "¿Cómo retornar las posiciones originales de estas oraciones y su contenido original una vez \n",
    "obtenidas los límites exactos tras el procesamiento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from preprocess.normalize import add_doc_ending_point\n",
    "import swalign\n",
    "\n",
    "PATH = '/home/abelma/preprocess/test/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrimos el fichero para hacer las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For other (optional) flags of <opencv_createsamples>, see the official... documentation\n",
      "at http://Docs.opencv.org/doc/user_guide/ug_traincascade.html.\n",
      "[ 99 ]\n",
      "www.it-ebooks.info.\n",
      "Generating Haar Cascades for Custom 8.4 Targets\n",
      "Creating <cascade> by running:\n",
      "<opencv_traincascade>\n",
      "3. anoche.\n",
      "4 Después. . . \n",
      "\n",
      "Over 110 recipes to master this full-stack Python web \n",
      "framework\n",
      "1.\t Take\n"
     ]
    }
   ],
   "source": [
    "text = open(os.path.join(PATH,'test_text.txt')).read()\n",
    "print (text[:round(len(text)/4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__el mismo texto analizado manualmente:__\n",
    "\n",
    "Mostremos por un instante el mismo texto con un análisis hecho a mano de las oraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For other (optional) flags of <opencv_createsamples>, see the official... documentation\n",
      "at http://Docs.opencv.org/doc/user_guide/ug_traincascade.html.\n",
      "[ 99 ]\n",
      "www.it-ebooks.info.\n",
      "Generating Haar Cascades for Custom 8.4 Targets\n",
      "Creating <cascade> by running:\n",
      "<opencv_traincascade>\n",
      "3. anoche.\n",
      "4 Después. . . \n",
      "\n",
      "Over 110 recipes to master this full-stack Python web \n",
      "framework\n",
      "1.\t Take\n"
     ]
    }
   ],
   "source": [
    "texth = open(os.path.join(PATH,'test_text_human_analysis.txt')).read()\n",
    "print (text[:round(len(text)/4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primera Función\n",
    "\n",
    "La primera función creada para estos fines por mí, fue para el PAN 2014, donde desafortunadamente no pude participar por\n",
    "no haber Wifi o políticas de SSH en la UCLV que me permitieran contectarme a la PC virtual del evento. Veamos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentences(text,orig_text):\n",
    "    \"\"\" Tokeniz a given text and return a dict containing all start and \n",
    "    end positions for each sentence.\n",
    "\n",
    "    :param text: generated text from clean_punctuation function.\n",
    "    :param type: string\n",
    "    :param orig_text: original text in process.\n",
    "    :param type: string\n",
    "    \n",
    "    :returns sentence_list: contain the sentence' number, the \n",
    "    generated sentence(only letters, '_' and the end-points), the \n",
    "    init-position of the original sentence equivalent to the \"generated\n",
    "    sentence\", and the end-position of the original sentence equivalent to the \"generated sentence\".\n",
    "    :rtype: tuple list.\n",
    "    \n",
    "    .. author: Abel Meneses abad\n",
    "    Finish on Fri, 28 Feb 2014\n",
    "    Next_revision on Sun Aug 3 2014\n",
    "    \"\"\"\n",
    "    sentence_list = []\n",
    "    sentence_count = 0\n",
    "    init, end = 0, 0\n",
    "\n",
    "    for i in range(len(text)):\n",
    "        if text[i] == '.':  #if '.' is found \n",
    "            end = i         #end sentence = '.' pos\n",
    "            while text[end] not in LETTERS: # in spite of found the last letter sentence pos\n",
    "                end-=1 \n",
    "            sentence = text[init:end+1]     # then construct exactly the sentence without end '.'\n",
    "            tuple = (sentence_count,sentence,init,end+1)\n",
    "            sentence_list.append(tuple)\n",
    "            sentence_count += 1\n",
    "            init = i\n",
    "            restante = text[init:]\n",
    "\n",
    "        elif init < len(text) and text[init] not in LETTERS:\n",
    "            init+=1\n",
    "            restante = text[init:]\n",
    "\n",
    "    count = 0\n",
    "    words = []\n",
    "    new_origen = 0\n",
    "    len_quitadas = 0\n",
    "    orig_text2 = orig_text\n",
    "    sentence_list2 = []\n",
    "    for i in range(len(sentence_list)):\n",
    "        oracion_buscada = sentence_list[i][1]\n",
    "        for word in oracion_buscada.split():\n",
    "            words.append(word)\n",
    "\n",
    "        lengt_oracion_buscada = len(oracion_buscada)\n",
    "        new_origen = orig_text.find(words[0])\n",
    "        orig_pos_init = new_origen + len_quitadas   #Dónde aparece la primera palabra de la oración que estoy buscando.\n",
    "        orig_pos_end = orig_pos_init + lengt_oracion_buscada # Posición inicial + largo de la oración = posición final.\n",
    "\n",
    "        tuple = (i, oracion_buscada, orig_pos_init, orig_pos_end) #construye la tupla con los valores del doc original.\n",
    "        sentence_list2.append(tuple)\n",
    "        restante = orig_text[new_origen+lengt_oracion_buscada:] # Elimino del texto la oración encontrada, queda de primera la siguiente\n",
    "\n",
    "        orig_text = orig_text[new_origen+lengt_oracion_buscada:]    # Elimino del texto la oración encontrada, queda de primera la siguiente\n",
    "        len_quitadas = orig_pos_end\n",
    "        words = []\n",
    "\n",
    "    sentence_list = sentence_list2\n",
    "\n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "LETTERS = ''.join([string.ascii_letters,string.digits,'ñÑáéíóúÁÉÍÓÚüÜ'])\n",
    "textr = open(os.path.join(PATH,'test_text_result.txt')).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For other optional flags of opencv_createsamples see the official documentation at http___Docs_opencv_org_doc_user_guide_ug_traincascade_html\n",
      "For other (optional) flags of <opencv_createsamples>, see the official... documentation\n",
      "at http://Docs.opencv.org/doc/user_guide/ug_traincasc\n"
     ]
    }
   ],
   "source": [
    "#Comprobando\n",
    "sentenceList = find_sentences(textr,text)\n",
    "print (sentenceList[0][1])\n",
    "print (text[sentenceList[0][2]:sentenceList[0][3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultado\n",
    "\n",
    "Como ven suele fallar, así que vamos a probar una versión utilizando el algoritmo de Smith-Waterman de alineamiento de textos. También usado en las medidas de similitud de cadenas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 1 AGCACAC-A 8\n",
      "         | ||||| |\n",
      "Ref  : 1 A-CACACTA 8\n",
      "\n",
      "Score: 12\n",
      "Matches: 7 (77.8%)\n",
      "Mismatches: 2\n",
      "CIGAR: 1M1I5M1D1M\n"
     ]
    }
   ],
   "source": [
    "#For swalign algthm\n",
    "# choose your own values here… 2 and -1 are common.\n",
    "match = 2\n",
    "mismatch = -1\n",
    "scoring = swalign.NucleotideScoringMatrix(match, mismatch)\n",
    "\n",
    "sw = swalign.LocalAlignment(scoring)  # you can also choose gap penalties, etc...\n",
    "alignment = sw.align('ACACACTA','AGCACACA')\n",
    "alignment.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probemos un ejemplo real con nuestros textos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:   1 For other (optional) flags of <opencv_createsamples>, see the official... documentation at http://Docs.opencv.org/doc/user_guide/ug_traincascade.html.  151\n",
      "           |||||||||| |||||||| |||||||||| ||||||||||||||||||||  |||||||||||||||||   ||||||||||||||||||||||...||||.||||||.|||.|||.||||||||||.|||||||||||||||.|||| |\n",
      "Ref  :   1 For other -optional- flags of -opencv_createsamples-- see the official--- documentation at http___Docs_opencv_org_doc_user_guide_ug_traincascade_html-  142\n",
      "\n",
      "Score: 248\n",
      "Matches: 133 (88.1%)\n",
      "Mismatches: 18\n",
      "CIGAR: 10M1I8M1I10M1I20M2I17M3I76M1I1M\n"
     ]
    }
   ],
   "source": [
    "textr = open('/home/abelm/preprocess/test/test_text_result.txt').read()\n",
    "s1 = textr[:143]\n",
    "text = open('/home/abelm/preprocess/test/test_text.txt').read()\n",
    "s2 = text[:]\n",
    "s2 = s2.replace('\\n',' ')\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver utilizando los puntos que existen en la primera oración (71, 72, 73, 103, 110, 145 y 150) la similitud con\n",
    "la oración preprocesada va desde 92% al 88%.\n",
    "Si utilizamos el texto completo la función encuentra la porción donde hay mayor coincidencia. En el ejemplo mostrado se nota que el **Query** desde 1 hasta 151 es la oración buscada.\n",
    "\n",
    "Note al correr esta celda que para textos grandes esto podría demorar.\n",
    "Utilicemos un ardid surgido de la experimentación: buscar el punto inicial(que es el 0 o el último punto de la oración anterior\n",
    "encontrada), y utilicemos el tamaño de **s1** para comparar el fragmento final de s1 con cualquiera del mismo tamaño \n",
    "desde donde quiera que encuentro un punto en **s2** (71, 72, 73, 103, 110, 145 y 150), hacia atrás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string,num, w):\n",
    "    \"\"\"Función auxiliar para cortar un texto dada un intervalo [w,num]\n",
    "    Solo sirve para el próximo bloque. No se usa en el algoritmo final\n",
    "    aunque sí se usó la idea de cortar para reducir los tiempos de cómputo.\n",
    "    \"\"\"\n",
    "    stri = string[:num]\n",
    "    stri = stri.replace('\\n',' ')\n",
    "    strig = stri[-round(w/4):]\n",
    "    return strig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que en el bloque siguiente los puntos finales (71, 72,...) fueron calculados manualmente para poder analizar que ocurría.\n",
    "Este sería el procedimiento normal durante una investigación.\n",
    "En el algoritmo final estas posiciones se calculan automáticamente al detectar cada posición de un punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 31 i-cia 34\n",
      "          | | |\n",
      "Ref  : 21 inc-a 24\n",
      "\n",
      "Score: 4\n",
      "Matches: 3 (60.0%)\n",
      "Mismatches: 2\n",
      "CIGAR: 1M1D1M1I1M\n",
      "71\n",
      "Query: 30 i-cia 33\n",
      "          | | |\n",
      "Ref  : 21 inc-a 24\n",
      "\n",
      "Score: 4\n",
      "Matches: 3 (60.0%)\n",
      "Mismatches: 2\n",
      "CIGAR: 1M1D1M1I1M\n",
      "72\n",
      "Query: 29 i-cia 32\n",
      "          | | |\n",
      "Ref  : 21 inc-a 24\n",
      "\n",
      "Score: 4\n",
      "Matches: 3 (60.0%)\n",
      "Mismatches: 2\n",
      "CIGAR: 1M1D1M1I1M\n",
      "73\n",
      "Query: 15 t-ation a 22\n",
      "          | | | |.|\n",
      "Ref  : 18 tra-i-nca 24\n",
      "\n",
      "Score: 6\n",
      "Matches: 5 (55.6%)\n",
      "Mismatches: 4\n",
      "CIGAR: 1M1D1M1I1M1I3M\n",
      "103\n",
      "Query:  8 t-ation a 15\n",
      "          | | | |.|\n",
      "Ref  : 18 tra-i-nca 24\n",
      "\n",
      "Score: 6\n",
      "Matches: 5 (55.6%)\n",
      "Mismatches: 4\n",
      "CIGAR: 1M1D1M1I1M1I3M\n",
      "110\n",
      "Query:  7 oc/user_guide/ug_traincascade 35\n",
      "          ||.||||||||||.|||||||||||||||\n",
      "Ref  :  1 oc_user_guide_ug_traincascade 29\n",
      "\n",
      "Score: 52\n",
      "Matches: 27 (93.1%)\n",
      "Mismatches: 2\n",
      "CIGAR: 29M\n",
      "145\n",
      "oc_user_guide_ug_traincascade_html . \n",
      " .org/doc/user_guide/ug_traincascade. \n",
      "****************\n",
      "Query:  2 oc/user_guide/ug_traincascade.html-. 36\n",
      "          ||.||||||||||.|||||||||||||||.|||| |\n",
      "Ref  :  1 oc_user_guide_ug_traincascade_html . 36\n",
      "\n",
      "Score: 60\n",
      "Matches: 32 (88.9%)\n",
      "Mismatches: 4\n",
      "CIGAR: 34M1D1M\n",
      "150\n",
      "oc_user_guide_ug_traincascade_html . \n",
      " doc/user_guide/ug_traincascade.html. \n",
      "****************\n",
      "Query:  1 de/ug_traincascade.html.  25\n",
      "          ||.|||||||||||||||.|||| |\n",
      "Ref  : 12 de_ug_traincascade_html-  35\n",
      "\n",
      "Score: 41\n",
      "Matches: 22 (88.0%)\n",
      "Mismatches: 3\n",
      "CIGAR: 23M1I1M\n",
      "162\n",
      "oc_user_guide_ug_traincascade_html . \n",
      " de/ug_traincascade.html. [ 99 ] www. \n",
      "****************\n",
      "Query:  1 ncascade.html.  15\n",
      "          ||||||||.|||| |\n",
      "Ref  : 22 ncascade_html-  35\n",
      "\n",
      "Score: 24\n",
      "Matches: 13 (86.7%)\n",
      "Mismatches: 2\n",
      "CIGAR: 13M1I1M\n",
      "172\n"
     ]
    }
   ],
   "source": [
    "textr = open('/home/abelm/preprocess/test/test_text_result.txt').read()\n",
    "sr = textr[:143]\n",
    "w = len(sr)\n",
    "s1 = sr[-round(w/4):]\n",
    "text = open('/home/abelm/preprocess/test/test_text.txt').read()\n",
    "s2 = cut(text,71,w)\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump();print(71)\n",
    "s2 = cut(text,72,w)\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump();print(72)\n",
    "s2 = cut(text,73,w)\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump();print(73)\n",
    "s2 = cut(text,103,w)\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump();print(103)\n",
    "s2 = cut(text,110,w)\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump();print(110)\n",
    "s2 = cut(text,145,w)\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump();print(145)\n",
    "print (s1,'\\n',s2,'\\n****************')\n",
    "s2 = cut(text,150,w)\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump();print(150)\n",
    "print (s1,'\\n',s2,'\\n****************')\n",
    "s2 = cut(text,162,w)\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump();print(162)\n",
    "print (s1,'\\n',s2,'\\n****************')\n",
    "s2 = cut(text,172,w)\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump();print(172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 6 . 6\n",
      "         |\n",
      "Ref  : 6 . 6\n",
      "\n",
      "Score: 2\n",
      "Matches: 1 (100.0%)\n",
      "Mismatches: 0\n",
      "CIGAR: 1M\n",
      "11\n",
      "info . \n",
      " ] www. \n",
      "****************\n",
      "Query: 6 . 6\n",
      "         |\n",
      "Ref  : 6 . 6\n",
      "\n",
      "Score: 2\n",
      "Matches: 1 (100.0%)\n",
      "Mismatches: 0\n",
      "CIGAR: 1M\n",
      "21\n",
      "info . \n",
      " books. \n",
      "****************\n",
      "Query: 2 info-. 6\n",
      "         |||| |\n",
      "Ref  : 1 info . 6\n",
      "\n",
      "Score: 9\n",
      "Matches: 5 (83.3%)\n",
      "Mismatches: 1\n",
      "CIGAR: 4M1D1M\n",
      "26\n",
      "info . \n",
      " .info. \n",
      "****************\n",
      "Query: 2 om 8. 6\n",
      "         | | |\n",
      "Ref  : 4 o- -. 6\n",
      "\n",
      "Score: 4\n",
      "Matches: 3 (60.0%)\n",
      "Mismatches: 2\n",
      "CIGAR: 1M1I1M1I1M\n",
      "65\n",
      "info . \n",
      " tom 8. \n",
      "****************\n"
     ]
    }
   ],
   "source": [
    "textr = open('/home/abelm/preprocess/test/test_text_result.txt').read()\n",
    "sr = textr[144:167]\n",
    "w = len(sr)\n",
    "s1 = sr[-round(w/4):]\n",
    "text2 = open('/home/abelm/preprocess/test/test_text.txt').read()\n",
    "text = text2[151:217]\n",
    "s2 = cut(text,11,w)\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump();print(11)\n",
    "print (s1,'\\n',s2,'\\n****************')\n",
    "s2 = cut(text,21,w)\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump();print(21)\n",
    "print (s1,'\\n',s2,'\\n****************')\n",
    "s2 = cut(text,26,w)\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump();print(26)\n",
    "print (s1,'\\n',s2,'\\n****************')\n",
    "s2 = cut(text,65,w)\n",
    "alignment = sw.align(s1,s2)\n",
    "alignment.dump();print(65)\n",
    "print (s1,'\\n',s2,'\\n****************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones parciales\n",
    "\n",
    "Como se puede observar en ambos ejemplos el mayor score lo da en la posición donde coincide el punto final de la oración\n",
    "de la que fue editada.\n",
    "Y el experimento de medir la distancia desde un cuarto de la oración hasta el final ofrece mayor velocidad.\n",
    "Implementemos ahora el algoritmo final, implementado en el [2.2 Aligning Preprocessed Sentence to Originals](02.2c-Jaccard-Align-Preproc-to-Original-Sent.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
